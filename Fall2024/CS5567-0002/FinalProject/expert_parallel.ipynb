{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "FILE_VERSION_SUFFIX = \"v3\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(X_train, Y_train), (X_test,Y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmi = keras.Input(shape=(None,None,3))\n",
    "\n",
    "end_models = []\n",
    "\n",
    "filter_counts =  [32, 16, 16, 32, 32, 64, 64]\n",
    "kernel_sizes  =  [3,  13, 11,  9,  7,  5,  3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model_32_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 45ms/step - accuracy: 0.3655 - loss: 1.7379 - val_accuracy: 0.3350 - val_loss: 2.0489\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.5112 - loss: 1.3527 - val_accuracy: 0.4008 - val_loss: 1.8053\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.5372 - loss: 1.2953 - val_accuracy: 0.4177 - val_loss: 1.6205\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.5417 - loss: 1.2996 - val_accuracy: 0.3364 - val_loss: 2.0042\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.5214 - loss: 1.3712 - val_accuracy: 0.4391 - val_loss: 1.6342\n",
      "Training model_16_13_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 44ms/step - accuracy: 0.3101 - loss: 1.8650 - val_accuracy: 0.1856 - val_loss: 2.6412\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.4144 - loss: 1.5856 - val_accuracy: 0.2279 - val_loss: 2.3607\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.4264 - loss: 1.5556 - val_accuracy: 0.2544 - val_loss: 2.2942\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.4310 - loss: 1.5569 - val_accuracy: 0.2133 - val_loss: 2.3377\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.4327 - loss: 1.5578 - val_accuracy: 0.3061 - val_loss: 1.8858\n",
      "Training model_16_11_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 45ms/step - accuracy: 0.3070 - loss: 1.8706 - val_accuracy: 0.3620 - val_loss: 1.6829\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - accuracy: 0.4175 - loss: 1.5827 - val_accuracy: 0.3299 - val_loss: 1.8032\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.4286 - loss: 1.5658 - val_accuracy: 0.2701 - val_loss: 2.1979\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.4194 - loss: 1.5888 - val_accuracy: 0.2793 - val_loss: 2.1880\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.4173 - loss: 1.6151 - val_accuracy: 0.3372 - val_loss: 1.9222\n",
      "Training model_32_9_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 45ms/step - accuracy: 0.3297 - loss: 1.8255 - val_accuracy: 0.3457 - val_loss: 1.8384\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - accuracy: 0.4455 - loss: 1.5208 - val_accuracy: 0.3147 - val_loss: 2.0576\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.4808 - loss: 1.4334 - val_accuracy: 0.4412 - val_loss: 1.6565\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.4925 - loss: 1.4009 - val_accuracy: 0.4215 - val_loss: 1.6232\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4940 - loss: 1.4136 - val_accuracy: 0.3622 - val_loss: 1.9003\n",
      "Training model_32_7_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 42ms/step - accuracy: 0.3236 - loss: 1.8506 - val_accuracy: 0.2473 - val_loss: 2.1367\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4630 - loss: 1.4792 - val_accuracy: 0.2405 - val_loss: 2.3178\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4997 - loss: 1.3898 - val_accuracy: 0.2860 - val_loss: 2.1381\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5074 - loss: 1.3735 - val_accuracy: 0.4098 - val_loss: 1.6622\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.5207 - loss: 1.3376 - val_accuracy: 0.4343 - val_loss: 1.6276\n",
      "Training model_64_5_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 42ms/step - accuracy: 0.3444 - loss: 1.8063 - val_accuracy: 0.3399 - val_loss: 1.8801\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.5027 - loss: 1.3832 - val_accuracy: 0.3866 - val_loss: 1.6681\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5433 - loss: 1.2798 - val_accuracy: 0.4805 - val_loss: 1.4320\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5546 - loss: 1.2581 - val_accuracy: 0.4701 - val_loss: 1.5353\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.5579 - loss: 1.2679 - val_accuracy: 0.5117 - val_loss: 1.4591\n",
      "Training model_64_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 42ms/step - accuracy: 0.3596 - loss: 1.8009 - val_accuracy: 0.2675 - val_loss: 2.1105\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4637 - loss: 1.5044 - val_accuracy: 0.1287 - val_loss: 8.8492\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.3872 - loss: 1.7409 - val_accuracy: 0.1586 - val_loss: 4.2564\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4330 - loss: 1.6372 - val_accuracy: 0.2918 - val_loss: 2.2092\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4462 - loss: 1.6667 - val_accuracy: 0.3548 - val_loss: 1.8860\n",
      "Loaded model_32_3_v2.keras\n",
      "Training model_32_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 41ms/step - accuracy: 0.4467 - loss: 1.5790 - val_accuracy: 0.5189 - val_loss: 1.3479\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.5744 - loss: 1.1915 - val_accuracy: 0.5440 - val_loss: 1.3017\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 41ms/step - accuracy: 0.5756 - loss: 1.2036 - val_accuracy: 0.5202 - val_loss: 1.3559\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - accuracy: 0.5746 - loss: 1.2327 - val_accuracy: 0.5219 - val_loss: 1.3604\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - accuracy: 0.5513 - loss: 1.3048 - val_accuracy: 0.5050 - val_loss: 1.4806\n",
      "Loaded model_16_13_v2.keras\n",
      "Training model_16_13_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 42ms/step - accuracy: 0.3748 - loss: 1.7301 - val_accuracy: 0.3792 - val_loss: 1.6648\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4833 - loss: 1.4280 - val_accuracy: 0.4278 - val_loss: 1.6176\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4995 - loss: 1.3924 - val_accuracy: 0.3868 - val_loss: 1.7629\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4990 - loss: 1.3951 - val_accuracy: 0.3695 - val_loss: 1.8284\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4806 - loss: 1.4557 - val_accuracy: 0.3440 - val_loss: 1.8455\n",
      "Loaded model_16_11_v2.keras\n",
      "Training model_16_11_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 42ms/step - accuracy: 0.3560 - loss: 1.8357 - val_accuracy: 0.3977 - val_loss: 1.6078\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4523 - loss: 1.5106 - val_accuracy: 0.3515 - val_loss: 1.8026\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4609 - loss: 1.5119 - val_accuracy: 0.3973 - val_loss: 1.6930\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4594 - loss: 1.5011 - val_accuracy: 0.3149 - val_loss: 1.9600\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4476 - loss: 1.5577 - val_accuracy: 0.3379 - val_loss: 1.8339\n",
      "Loaded model_32_9_v2.keras\n",
      "Training model_32_9_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 42ms/step - accuracy: 0.4207 - loss: 1.6358 - val_accuracy: 0.4246 - val_loss: 1.6343\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5340 - loss: 1.2824 - val_accuracy: 0.4047 - val_loss: 1.6772\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5405 - loss: 1.2948 - val_accuracy: 0.4135 - val_loss: 1.7167\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5236 - loss: 1.3531 - val_accuracy: 0.3633 - val_loss: 1.9053\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 42ms/step - accuracy: 0.5124 - loss: 1.3910 - val_accuracy: 0.4058 - val_loss: 1.7514\n",
      "Loaded model_32_7_v2.keras\n",
      "Training model_32_7_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 42ms/step - accuracy: 0.4513 - loss: 1.5489 - val_accuracy: 0.5057 - val_loss: 1.3947\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5794 - loss: 1.1857 - val_accuracy: 0.5122 - val_loss: 1.3705\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.5937 - loss: 1.1538 - val_accuracy: 0.3117 - val_loss: 2.3161\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5790 - loss: 1.1796 - val_accuracy: 0.5010 - val_loss: 1.4193\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5748 - loss: 1.1960 - val_accuracy: 0.3013 - val_loss: 2.4798\n",
      "Loaded model_64_5_v2.keras\n",
      "Training model_64_5_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 41ms/step - accuracy: 0.4822 - loss: 1.4822 - val_accuracy: 0.4825 - val_loss: 1.4402\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.6255 - loss: 1.0755 - val_accuracy: 0.5772 - val_loss: 1.1873\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.6257 - loss: 1.0842 - val_accuracy: 0.5293 - val_loss: 1.3527\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 41ms/step - accuracy: 0.6132 - loss: 1.1320 - val_accuracy: 0.5681 - val_loss: 1.2084\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.6174 - loss: 1.1205 - val_accuracy: 0.4422 - val_loss: 1.9948\n",
      "Loaded model_64_3_v2.keras\n",
      "Training model_64_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 41ms/step - accuracy: 0.4249 - loss: 1.6908 - val_accuracy: 0.3784 - val_loss: 1.9285\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.5145 - loss: 1.3914 - val_accuracy: 0.3254 - val_loss: 2.5852\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.5089 - loss: 1.4444 - val_accuracy: 0.3831 - val_loss: 2.1327\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.5021 - loss: 1.5083 - val_accuracy: 0.4270 - val_loss: 1.8251\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4867 - loss: 1.6309 - val_accuracy: 0.4521 - val_loss: 1.8024\n",
      "Loaded model_32_3_v2.keras\n",
      "Training model_32_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 41ms/step - accuracy: 0.4385 - loss: 1.7330 - val_accuracy: 0.5359 - val_loss: 1.2876\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.5771 - loss: 1.1972 - val_accuracy: 0.5150 - val_loss: 1.3718\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.5742 - loss: 1.2163 - val_accuracy: 0.4763 - val_loss: 1.5128\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 41ms/step - accuracy: 0.5593 - loss: 1.2969 - val_accuracy: 0.4678 - val_loss: 1.5434\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.5431 - loss: 1.3788 - val_accuracy: 0.3776 - val_loss: 1.9322\n",
      "Loaded model_16_13_v2.keras\n",
      "Training model_16_13_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 43ms/step - accuracy: 0.3798 - loss: 1.7531 - val_accuracy: 0.3326 - val_loss: 1.8870\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.4813 - loss: 1.4491 - val_accuracy: 0.3714 - val_loss: 1.7915\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.4698 - loss: 1.4796 - val_accuracy: 0.3192 - val_loss: 1.8052\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.4391 - loss: 1.5823 - val_accuracy: 0.2752 - val_loss: 2.0518\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.4228 - loss: 1.6527 - val_accuracy: 0.2778 - val_loss: 2.2284\n",
      "Loaded model_16_11_v2.keras\n",
      "Training model_16_11_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 43ms/step - accuracy: 0.3557 - loss: 1.9253 - val_accuracy: 0.3453 - val_loss: 1.8776\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.4457 - loss: 1.5397 - val_accuracy: 0.3594 - val_loss: 1.8371\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.4492 - loss: 1.5820 - val_accuracy: 0.3383 - val_loss: 1.9341\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.4209 - loss: 1.6671 - val_accuracy: 0.3549 - val_loss: 1.8405\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.4191 - loss: 1.6983 - val_accuracy: 0.3371 - val_loss: 2.0132\n",
      "Loaded model_32_9_v2.keras\n",
      "Training model_32_9_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 44ms/step - accuracy: 0.4045 - loss: 1.7184 - val_accuracy: 0.5128 - val_loss: 1.3387\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.5508 - loss: 1.2643 - val_accuracy: 0.3978 - val_loss: 1.7380\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.5491 - loss: 1.2786 - val_accuracy: 0.5040 - val_loss: 1.4349\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.5499 - loss: 1.2861 - val_accuracy: 0.4832 - val_loss: 1.4562\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.5377 - loss: 1.3409 - val_accuracy: 0.4588 - val_loss: 1.5755\n",
      "Loaded model_32_7_v2.keras\n",
      "Training model_32_7_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 43ms/step - accuracy: 0.4402 - loss: 1.6368 - val_accuracy: 0.5071 - val_loss: 1.3768\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.5891 - loss: 1.1641 - val_accuracy: 0.5101 - val_loss: 1.3891\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.5907 - loss: 1.1589 - val_accuracy: 0.4731 - val_loss: 1.5329\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.5883 - loss: 1.1716 - val_accuracy: 0.4909 - val_loss: 1.4328\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 43ms/step - accuracy: 0.5782 - loss: 1.2140 - val_accuracy: 0.4839 - val_loss: 1.4742\n",
      "Loaded model_64_5_v2.keras\n",
      "Training model_64_5_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 44ms/step - accuracy: 0.5061 - loss: 1.4728 - val_accuracy: 0.5609 - val_loss: 1.2121\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.6183 - loss: 1.0976 - val_accuracy: 0.4979 - val_loss: 1.5163\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.6082 - loss: 1.1603 - val_accuracy: 0.5246 - val_loss: 1.4140\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.5955 - loss: 1.2350 - val_accuracy: 0.5056 - val_loss: 1.6016\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5829 - loss: 1.2959 - val_accuracy: 0.5171 - val_loss: 1.4848\n",
      "Loaded model_64_3_v2.keras\n",
      "Training model_64_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 37ms/step - accuracy: 0.3990 - loss: 1.8374 - val_accuracy: 0.4613 - val_loss: 1.5306\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.5077 - loss: 1.4469 - val_accuracy: 0.4456 - val_loss: 1.6152\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.5009 - loss: 1.5101 - val_accuracy: 0.4017 - val_loss: 1.9609\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.5041 - loss: 1.5869 - val_accuracy: 0.3683 - val_loss: 1.9352\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.4961 - loss: 1.6708 - val_accuracy: 0.4347 - val_loss: 1.8592\n",
      "Loaded model_32_3_v2.keras\n",
      "Training model_32_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - accuracy: 0.4317 - loss: 1.7559 - val_accuracy: 0.5204 - val_loss: 1.4034\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 36ms/step - accuracy: 0.5525 - loss: 1.3038 - val_accuracy: 0.4202 - val_loss: 1.7552\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.5521 - loss: 1.3344 - val_accuracy: 0.5308 - val_loss: 1.3440\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.5390 - loss: 1.4047 - val_accuracy: 0.5051 - val_loss: 1.4405\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.5335 - loss: 1.4402 - val_accuracy: 0.4717 - val_loss: 1.6453\n",
      "Loaded model_16_13_v2.keras\n",
      "Training model_16_13_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - accuracy: 0.3368 - loss: 1.9864 - val_accuracy: 0.3212 - val_loss: 1.9291\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.4535 - loss: 1.5222 - val_accuracy: 0.3085 - val_loss: 1.9699\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.4532 - loss: 1.5294 - val_accuracy: 0.2785 - val_loss: 2.1554\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.4526 - loss: 1.5513 - val_accuracy: 0.3301 - val_loss: 1.9419\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 36ms/step - accuracy: 0.4439 - loss: 1.5925 - val_accuracy: 0.3043 - val_loss: 2.1016\n",
      "Loaded model_16_11_v2.keras\n",
      "Training model_16_11_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 36ms/step - accuracy: 0.3392 - loss: 2.1550 - val_accuracy: 0.3795 - val_loss: 1.6796\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.4522 - loss: 1.5369 - val_accuracy: 0.3697 - val_loss: 1.7561\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.4615 - loss: 1.5218 - val_accuracy: 0.3391 - val_loss: 2.0085\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 35ms/step - accuracy: 0.4421 - loss: 1.5957 - val_accuracy: 0.3119 - val_loss: 2.0727\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 35ms/step - accuracy: 0.4315 - loss: 1.6392 - val_accuracy: 0.3810 - val_loss: 1.8354\n",
      "Loaded model_32_9_v2.keras\n",
      "Training model_32_9_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 37ms/step - accuracy: 0.4168 - loss: 1.7271 - val_accuracy: 0.4949 - val_loss: 1.3923\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.5524 - loss: 1.2575 - val_accuracy: 0.4329 - val_loss: 1.6282\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.5453 - loss: 1.2866 - val_accuracy: 0.4438 - val_loss: 1.5741\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.5331 - loss: 1.3490 - val_accuracy: 0.4555 - val_loss: 1.5512\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5305 - loss: 1.3847 - val_accuracy: 0.4316 - val_loss: 1.6157\n",
      "Loaded model_32_7_v2.keras\n",
      "Training model_32_7_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 37ms/step - accuracy: 0.4474 - loss: 1.7307 - val_accuracy: 0.4915 - val_loss: 1.4879\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.5885 - loss: 1.1629 - val_accuracy: 0.4491 - val_loss: 1.5990\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5973 - loss: 1.1414 - val_accuracy: 0.5088 - val_loss: 1.4037\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5930 - loss: 1.1769 - val_accuracy: 0.5423 - val_loss: 1.3266\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5922 - loss: 1.1946 - val_accuracy: 0.5005 - val_loss: 1.4404\n",
      "Loaded model_64_5_v2.keras\n",
      "Training model_64_5_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 39ms/step - accuracy: 0.4475 - loss: 1.7479 - val_accuracy: 0.5883 - val_loss: 1.1693\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.6027 - loss: 1.1521 - val_accuracy: 0.5613 - val_loss: 1.2685\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.6055 - loss: 1.1858 - val_accuracy: 0.5778 - val_loss: 1.2136\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.6044 - loss: 1.2141 - val_accuracy: 0.5675 - val_loss: 1.3559\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.5938 - loss: 1.3067 - val_accuracy: 0.5002 - val_loss: 1.5604\n",
      "Loaded model_64_3_v2.keras\n",
      "Training model_64_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 38ms/step - accuracy: 0.4065 - loss: 1.8926 - val_accuracy: 0.4507 - val_loss: 1.5887\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.5158 - loss: 1.4501 - val_accuracy: 0.3823 - val_loss: 2.1171\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.4967 - loss: 1.6167 - val_accuracy: 0.4568 - val_loss: 1.6627\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.4919 - loss: 1.7607 - val_accuracy: 0.4711 - val_loss: 1.8202\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.4795 - loss: 1.9718 - val_accuracy: 0.4658 - val_loss: 2.0373\n",
      "Loaded model_32_3_v2.keras\n",
      "Training model_32_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 38ms/step - accuracy: 0.4205 - loss: 1.9038 - val_accuracy: 0.4514 - val_loss: 1.5437\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.5120 - loss: 1.4580 - val_accuracy: 0.4084 - val_loss: 1.8673\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.5075 - loss: 1.5196 - val_accuracy: 0.4213 - val_loss: 1.8521\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - accuracy: 0.4878 - loss: 1.6494 - val_accuracy: 0.4756 - val_loss: 1.5130\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4868 - loss: 1.7393 - val_accuracy: 0.3562 - val_loss: 2.0586\n",
      "Loaded model_16_13_v2.keras\n",
      "Training model_16_13_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 38ms/step - accuracy: 0.3370 - loss: 2.0965 - val_accuracy: 0.3102 - val_loss: 1.9152\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.4576 - loss: 1.5092 - val_accuracy: 0.3374 - val_loss: 1.9113\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.4651 - loss: 1.4970 - val_accuracy: 0.3649 - val_loss: 1.7079\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4593 - loss: 1.5271 - val_accuracy: 0.3472 - val_loss: 1.8018\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4597 - loss: 1.5407 - val_accuracy: 0.2144 - val_loss: 2.6000\n",
      "Loaded model_16_11_v2.keras\n",
      "Training model_16_11_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 37ms/step - accuracy: 0.3441 - loss: 2.2023 - val_accuracy: 0.3751 - val_loss: 1.7409\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4487 - loss: 1.5528 - val_accuracy: 0.3150 - val_loss: 1.8565\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4398 - loss: 1.5803 - val_accuracy: 0.3698 - val_loss: 1.7741\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4301 - loss: 1.6330 - val_accuracy: 0.3623 - val_loss: 1.8652\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4338 - loss: 1.6582 - val_accuracy: 0.3650 - val_loss: 1.8029\n",
      "Loaded model_32_9_v2.keras\n",
      "Training model_32_9_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 38ms/step - accuracy: 0.3898 - loss: 2.1295 - val_accuracy: 0.4234 - val_loss: 1.7545\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5165 - loss: 1.4057 - val_accuracy: 0.4567 - val_loss: 1.5352\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5002 - loss: 1.4883 - val_accuracy: 0.4714 - val_loss: 1.5132\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4852 - loss: 1.5976 - val_accuracy: 0.4112 - val_loss: 1.9065\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4758 - loss: 1.6617 - val_accuracy: 0.4343 - val_loss: 1.6132\n",
      "Loaded model_32_7_v2.keras\n",
      "Training model_32_7_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 39ms/step - accuracy: 0.4342 - loss: 1.7263 - val_accuracy: 0.5118 - val_loss: 1.3816\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5744 - loss: 1.2049 - val_accuracy: 0.5364 - val_loss: 1.3109\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5708 - loss: 1.2357 - val_accuracy: 0.4534 - val_loss: 1.5261\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5620 - loss: 1.2799 - val_accuracy: 0.3801 - val_loss: 1.9742\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5429 - loss: 1.3602 - val_accuracy: 0.4865 - val_loss: 1.6116\n",
      "Loaded model_64_5_v2.keras\n",
      "Training model_64_5_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 39ms/step - accuracy: 0.4593 - loss: 1.7660 - val_accuracy: 0.5271 - val_loss: 1.3754\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.5840 - loss: 1.2591 - val_accuracy: 0.4984 - val_loss: 1.5881\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.5535 - loss: 1.4218 - val_accuracy: 0.5203 - val_loss: 1.4289\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.5498 - loss: 1.5785 - val_accuracy: 0.5157 - val_loss: 1.5102\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.5205 - loss: 1.8440 - val_accuracy: 0.4473 - val_loss: 2.0916\n",
      "Loaded model_64_3_v2.keras\n",
      "Training model_64_3_v3.keras\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 40ms/step - accuracy: 0.3832 - loss: 2.3316 - val_accuracy: 0.4563 - val_loss: 1.6148\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.4748 - loss: 1.7219 - val_accuracy: 0.3618 - val_loss: 2.0571\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 40ms/step - accuracy: 0.4748 - loss: 1.8059 - val_accuracy: 0.3884 - val_loss: 2.4661\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 39ms/step - accuracy: 0.4665 - loss: 1.9501 - val_accuracy: 0.3395 - val_loss: 2.5922\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.4662 - loss: 2.1031 - val_accuracy: 0.4256 - val_loss: 2.3699\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "dense_size = 32\n",
    "\n",
    "for j in range(5):\n",
    "    for i in range(len(filter_counts)):\n",
    "        #convert X_sample to float32\n",
    "\n",
    "        #if the model file already exists, skip it\n",
    "        inner_model = None\n",
    "\n",
    "        try:\n",
    "            inner_model = models.load_model(f'model_{filter_counts[i]}_{kernel_sizes[i]}_{FILE_VERSION_SUFFIX}.keras', compile=False)\n",
    "            print(f'Loaded model_{filter_counts[i]}_{kernel_sizes[i]}_{FILE_VERSION_SUFFIX}.keras')\n",
    "            inner_model.trainable = True\n",
    "        except:\n",
    "\n",
    "            inner_model = models.Sequential()\n",
    "            inner_model.add(layers.InputLayer(shape=(32,32,3)))\n",
    "\n",
    "            inner_model.add(layers.Conv2D(filter_counts[i], (kernel_sizes[i], kernel_sizes[i]), activation='relu', padding='same'))\n",
    "            inner_model.add(layers.Dropout(0.25))\n",
    "            inner_model.add(layers.BatchNormalization())\n",
    "\n",
    "            inner_model.add(layers.Conv2D(2*filter_counts[i], (3, 3), activation='relu', padding='same'))\n",
    "            inner_model.add(layers.Dropout(0.25))\n",
    "            inner_model.add(layers.BatchNormalization())\n",
    "            inner_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "            inner_model.add(layers.Conv2D(4*filter_counts[i], (3, 3), activation='relu', padding='same'))\n",
    "            inner_model.add(layers.Dropout(0.25))\n",
    "            inner_model.add(layers.BatchNormalization())\n",
    "            inner_model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "        inner_model.add(layers.GlobalAveragePooling2D())\n",
    "        inner_model.add(layers.Dense(dense_size, activation='relu'))\n",
    "        inner_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "        print(f\"Training model_{filter_counts[i]}_{kernel_sizes[i]}_{FILE_VERSION_SUFFIX}.keras\")\n",
    "\n",
    "        inner_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        inner_model.fit(X_train, Y_train, epochs=5, validation_data=(X_test,Y_test), verbose=1)\n",
    "\n",
    "        inner_model.pop(rebuild=True)\n",
    "        inner_model.pop(rebuild=True)\n",
    "        inner_model.pop(rebuild=True)\n",
    "\n",
    "        inner_model.save(f'model_{filter_counts[i]}_{kernel_sizes[i]}_{FILE_VERSION_SUFFIX}.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n",
      "Loaded model_32_3_v3.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasjones/.pyenv/versions/finproj/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 26 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 21ms/step - accuracy: 0.0286 - loss: 4.6032\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.0788 - loss: 4.1631\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1000 - loss: 4.0165\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.1092 - loss: 3.9335\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1226 - loss: 3.8662\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1266 - loss: 3.8127\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1378 - loss: 3.7716\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1404 - loss: 3.7418\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1473 - loss: 3.7126\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1481 - loss: 3.6809\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1534 - loss: 3.6555\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1545 - loss: 3.6400\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1587 - loss: 3.6220\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1616 - loss: 3.6058\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1652 - loss: 3.5809\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1667 - loss: 3.5680\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1687 - loss: 3.5596\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1711 - loss: 3.5493\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1732 - loss: 3.5358\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1762 - loss: 3.5227\n",
      "Loaded model_16_13_v3.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - accuracy: 0.0270 - loss: 4.6027\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.0788 - loss: 4.1552\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.1014 - loss: 3.9972\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.1189 - loss: 3.9105\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.1296 - loss: 3.8487\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.1311 - loss: 3.8149\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.1357 - loss: 3.7816\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1431 - loss: 3.7413\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.1466 - loss: 3.7342\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1511 - loss: 3.7070\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1491 - loss: 3.6976\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1547 - loss: 3.6858\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1535 - loss: 3.6714\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1570 - loss: 3.6622\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1593 - loss: 3.6429\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1620 - loss: 3.6247\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1602 - loss: 3.6251\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1636 - loss: 3.6088\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.1662 - loss: 3.6067\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1691 - loss: 3.5855\n",
      "Loaded model_16_11_v3.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - accuracy: 0.0242 - loss: 4.5962\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.0598 - loss: 4.2629\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.0840 - loss: 4.1319\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.0973 - loss: 4.0550\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1081 - loss: 3.9895\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1187 - loss: 3.9297\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.1234 - loss: 3.8882\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.1298 - loss: 3.8498\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.1340 - loss: 3.8281\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1358 - loss: 3.7823\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1393 - loss: 3.7778\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1455 - loss: 3.7511\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1447 - loss: 3.7301\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1529 - loss: 3.7127\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1509 - loss: 3.7057\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1528 - loss: 3.6854\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1607 - loss: 3.6670\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1588 - loss: 3.6612\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1569 - loss: 3.6497\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1580 - loss: 3.6511\n",
      "Loaded model_32_9_v3.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.0247 - loss: 4.7060\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.0767 - loss: 4.1660\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1057 - loss: 3.9863\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1212 - loss: 3.8767\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1339 - loss: 3.8092\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1427 - loss: 3.7452\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1457 - loss: 3.7128\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1529 - loss: 3.6785\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1549 - loss: 3.6456\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1660 - loss: 3.6090\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1691 - loss: 3.5889\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1693 - loss: 3.5662\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1747 - loss: 3.5479\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1766 - loss: 3.5163\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1792 - loss: 3.5146\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1820 - loss: 3.5017\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1855 - loss: 3.4737\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1842 - loss: 3.4653\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1831 - loss: 3.4692\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1895 - loss: 3.4403\n",
      "Loaded model_32_7_v3.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.0271 - loss: 4.6306\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.0886 - loss: 4.0899\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.1317 - loss: 3.8613\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.1487 - loss: 3.7364\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1625 - loss: 3.6537\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.1728 - loss: 3.5775\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.1800 - loss: 3.5327\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.1873 - loss: 3.4866\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.1960 - loss: 3.4412\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.1964 - loss: 3.4255\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2012 - loss: 3.3980\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2061 - loss: 3.3786\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2082 - loss: 3.3479\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2114 - loss: 3.3362\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.2142 - loss: 3.3153\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2167 - loss: 3.2991\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2176 - loss: 3.3020\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.2201 - loss: 3.2762\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2240 - loss: 3.2712\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.2239 - loss: 3.2558\n",
      "Loaded model_64_5_v3.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.0295 - loss: 4.6957\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.0896 - loss: 4.1134\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.1148 - loss: 3.9475\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.1356 - loss: 3.8244\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.1490 - loss: 3.7511\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.1580 - loss: 3.6870\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1686 - loss: 3.6158\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1790 - loss: 3.5586\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1847 - loss: 3.5397\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1891 - loss: 3.5076\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.1894 - loss: 3.4682\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.1957 - loss: 3.4420\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2008 - loss: 3.4089\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.2021 - loss: 3.3849\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.2047 - loss: 3.3622\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2077 - loss: 3.3525\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.2126 - loss: 3.3235\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.2091 - loss: 3.3277\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.2171 - loss: 3.2976\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.2192 - loss: 3.2930\n",
      "Loaded model_64_3_v3.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.0278 - loss: 4.6779\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.0706 - loss: 4.1774\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.0994 - loss: 4.0408\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.1096 - loss: 3.9541\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.1259 - loss: 3.8725\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.1369 - loss: 3.8051\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1432 - loss: 3.7659\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1511 - loss: 3.7112\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1558 - loss: 3.6788\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1603 - loss: 3.6471\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1672 - loss: 3.6099\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1664 - loss: 3.5939\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1722 - loss: 3.5691\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1736 - loss: 3.5484\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1772 - loss: 3.5270\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1805 - loss: 3.5054\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.1867 - loss: 3.4988\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.1889 - loss: 3.4719\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.1918 - loss: 3.4544\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.1916 - loss: 3.4532\n"
     ]
    }
   ],
   "source": [
    "#load the cifar100 dataset\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "\n",
    "(X_train, Y_train), (X_test,Y_test) = cifar100.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "print(Y_test.shape)\n",
    "\n",
    "the_models = []\n",
    "\n",
    "for i in range(len(filter_counts)):\n",
    "    inner_model = models.load_model(f'model_{filter_counts[i]}_{kernel_sizes[i]}_{FILE_VERSION_SUFFIX}.keras')\n",
    "    print(f'Loaded model_{filter_counts[i]}_{kernel_sizes[i]}_{FILE_VERSION_SUFFIX}.keras')\n",
    "    inner_model.trainable = False\n",
    "\n",
    "    #Fine tune the model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=(32,32,3)))\n",
    "    model.add(inner_model)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=0.00005)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs=20, batch_size=64)\n",
    "\n",
    "    model.trainable = False\n",
    "\n",
    "    the_models.append(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_913\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_913\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,380</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,308</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">72,004</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">160,292</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">157,220</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">468,196</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">465,124</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │ dense_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m153,380\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m74,308\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m72,004\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m160,292\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m157,220\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m468,196\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │    \u001b[38;5;34m465,124\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ sequential_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_110 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m12,928\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_111 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m12,900\u001b[0m │ dense_110[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,576,352</span> (6.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,576,352\u001b[0m (6.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,828</span> (100.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,828\u001b[0m (100.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,550,524</span> (5.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,550,524\u001b[0m (5.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "(50000, 100)\n",
      "(50000, 32, 32, 3)\n",
      "Epoch 1/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 42ms/step - accuracy: 0.1540 - loss: 3.9097\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2472 - loss: 3.1232\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.2583 - loss: 3.0338\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2697 - loss: 2.9829\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.2751 - loss: 2.9534\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2771 - loss: 2.9264\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2779 - loss: 2.9215\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2836 - loss: 2.9062\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.2877 - loss: 2.8951\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2892 - loss: 2.8684\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2890 - loss: 2.8751\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2941 - loss: 2.8581\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.2922 - loss: 2.8458\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2916 - loss: 2.8560\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2925 - loss: 2.8475\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2918 - loss: 2.8397\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2933 - loss: 2.8379\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2909 - loss: 2.8526\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2919 - loss: 2.8432\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2956 - loss: 2.8333\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step\n",
      "(10000, 100)\n",
      "(10000, 100)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.44      0.35       100\n",
      "           1       0.10      0.06      0.08       100\n",
      "           2       0.14      0.19      0.16       100\n",
      "           3       0.10      0.20      0.13       100\n",
      "           4       0.05      0.10      0.07       100\n",
      "           5       0.19      0.28      0.23       100\n",
      "           6       0.35      0.15      0.21       100\n",
      "           7       0.23      0.09      0.13       100\n",
      "           8       0.30      0.21      0.25       100\n",
      "           9       0.12      0.13      0.12       100\n",
      "          10       0.08      0.17      0.11       100\n",
      "          11       0.11      0.03      0.05       100\n",
      "          12       0.21      0.37      0.27       100\n",
      "          13       0.77      0.10      0.18       100\n",
      "          14       0.33      0.01      0.02       100\n",
      "          15       0.22      0.11      0.15       100\n",
      "          16       0.50      0.05      0.09       100\n",
      "          17       0.75      0.21      0.33       100\n",
      "          18       0.20      0.05      0.08       100\n",
      "          19       0.36      0.14      0.20       100\n",
      "          20       0.81      0.21      0.33       100\n",
      "          21       0.28      0.26      0.27       100\n",
      "          22       0.46      0.06      0.11       100\n",
      "          23       0.21      0.40      0.27       100\n",
      "          24       0.40      0.29      0.34       100\n",
      "          25       0.12      0.16      0.14       100\n",
      "          26       0.24      0.09      0.13       100\n",
      "          27       0.09      0.37      0.14       100\n",
      "          28       0.10      0.33      0.15       100\n",
      "          29       0.58      0.07      0.12       100\n",
      "          30       0.14      0.32      0.20       100\n",
      "          31       0.22      0.29      0.25       100\n",
      "          32       0.14      0.11      0.12       100\n",
      "          33       0.35      0.11      0.17       100\n",
      "          34       0.10      0.03      0.05       100\n",
      "          35       0.00      0.00      0.00       100\n",
      "          36       0.27      0.12      0.17       100\n",
      "          37       0.54      0.07      0.12       100\n",
      "          38       0.12      0.02      0.03       100\n",
      "          39       0.48      0.14      0.22       100\n",
      "          40       0.05      0.18      0.08       100\n",
      "          41       0.60      0.12      0.20       100\n",
      "          42       0.40      0.08      0.13       100\n",
      "          43       0.54      0.07      0.12       100\n",
      "          44       0.05      0.14      0.07       100\n",
      "          45       0.19      0.05      0.08       100\n",
      "          46       0.00      0.00      0.00       100\n",
      "          47       0.71      0.10      0.18       100\n",
      "          48       0.58      0.38      0.46       100\n",
      "          49       0.44      0.17      0.24       100\n",
      "          50       0.11      0.03      0.05       100\n",
      "          51       0.00      0.00      0.00       100\n",
      "          52       0.60      0.30      0.40       100\n",
      "          53       0.67      0.10      0.17       100\n",
      "          54       0.46      0.19      0.27       100\n",
      "          55       0.03      0.31      0.06       100\n",
      "          56       0.34      0.13      0.19       100\n",
      "          57       0.18      0.11      0.14       100\n",
      "          58       0.43      0.54      0.48       100\n",
      "          59       0.23      0.18      0.20       100\n",
      "          60       0.65      0.41      0.50       100\n",
      "          61       0.34      0.24      0.28       100\n",
      "          62       0.89      0.08      0.15       100\n",
      "          63       0.11      0.10      0.10       100\n",
      "          64       0.10      0.04      0.06       100\n",
      "          65       0.06      0.09      0.07       100\n",
      "          66       0.00      0.00      0.00       100\n",
      "          67       0.15      0.08      0.10       100\n",
      "          68       0.21      0.66      0.32       100\n",
      "          69       0.13      0.46      0.20       100\n",
      "          70       0.57      0.08      0.14       100\n",
      "          71       0.17      0.86      0.28       100\n",
      "          72       0.03      0.13      0.05       100\n",
      "          73       0.19      0.37      0.25       100\n",
      "          74       0.18      0.13      0.15       100\n",
      "          75       0.67      0.26      0.37       100\n",
      "          76       0.37      0.51      0.43       100\n",
      "          77       0.09      0.09      0.09       100\n",
      "          78       0.17      0.06      0.09       100\n",
      "          79       0.06      0.09      0.07       100\n",
      "          80       0.10      0.04      0.06       100\n",
      "          81       0.40      0.22      0.28       100\n",
      "          82       0.68      0.19      0.30       100\n",
      "          83       0.45      0.05      0.09       100\n",
      "          84       0.16      0.06      0.09       100\n",
      "          85       0.27      0.23      0.25       100\n",
      "          86       0.67      0.08      0.14       100\n",
      "          87       0.41      0.22      0.29       100\n",
      "          88       0.50      0.01      0.02       100\n",
      "          89       0.36      0.05      0.09       100\n",
      "          90       0.20      0.17      0.18       100\n",
      "          91       0.25      0.06      0.10       100\n",
      "          92       0.50      0.01      0.02       100\n",
      "          93       0.12      0.04      0.06       100\n",
      "          94       0.48      0.50      0.49       100\n",
      "          95       0.15      0.39      0.22       100\n",
      "          96       0.41      0.12      0.19       100\n",
      "          97       0.24      0.08      0.12       100\n",
      "          98       0.25      0.06      0.10       100\n",
      "          99       0.13      0.40      0.19       100\n",
      "\n",
      "    accuracy                           0.17     10000\n",
      "   macro avg       0.30      0.17      0.17     10000\n",
      "weighted avg       0.30      0.17      0.17     10000\n",
      "\n",
      "[[44  0  2 ...  0  0  0]\n",
      " [ 0  6  2 ...  0  0  2]\n",
      " [ 0  0 19 ...  0  2  1]\n",
      " ...\n",
      " [ 0  0  4 ...  8  0  0]\n",
      " [ 2  0  6 ...  0  6  2]\n",
      " [ 0  0  1 ...  0  0 40]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#load the cifar100 dataset\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "\n",
    "(X_train, Y_train), (X_test,Y_test) = cifar100.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "#make the models trainable\n",
    "for model in the_models:\n",
    "    model.trainable = False\n",
    "\n",
    "\n",
    "#Construct an ensemble model\n",
    "inp = layers.Input(shape=(32,32,3))\n",
    "x = layers.Add()([model(inp) for model in the_models])\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "ensemble_model = models.Model(inp, x)\n",
    "\n",
    "print(ensemble_model.summary())\n",
    "print(Y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ensemble_model.fit(X_train, Y_train, epochs=20, batch_size=64)\n",
    "\n",
    "#Create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "Y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "print(Y_pred.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "yp_max = np.argmax(Y_pred, axis=1)\n",
    "yt_max = np.argmax(Y_test, axis=1)\n",
    "\n",
    "#print the metrics\n",
    "print(classification_report(yt_max, yp_max))\n",
    "\n",
    "print(confusion_matrix(yt_max, yp_max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  0,  2, ...,  0,  0,  0],\n",
       "       [ 0,  6,  2, ...,  0,  0,  2],\n",
       "       [ 0,  0, 19, ...,  0,  2,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  4, ...,  8,  0,  0],\n",
       "       [ 2,  0,  6, ...,  0,  6,  2],\n",
       "       [ 0,  0,  1, ...,  0,  0, 40]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yt_max, yp_max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
