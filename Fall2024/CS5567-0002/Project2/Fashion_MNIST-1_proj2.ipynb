{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Thomas Jones - COMP_SCI-5567-0002-46075-2024FS-Deep Learning\n",
        "\n",
        "## Project #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 512,
      "metadata": {
        "id": "hASLpyncBmvt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "92458.52s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: 2.0.0 not found\n"
          ]
        }
      ],
      "source": [
        "!pip install -U portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jum_uBK3SA8Q"
      },
      "source": [
        "## Common Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 513,
      "metadata": {
        "id": "1AShoC94SHM6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General MPL Implementation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 514,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class MLP(nn.Module): #MLP stands for \"Multi-Layer Perceptron\"\n",
        "    '''\n",
        "    MLP class for dense neural network.\n",
        "    Create passing an array of hidden layer topologies and activations.\n",
        "    The topology array should contain the number of neurons in each hidden layer.\n",
        "    The activations array should contain the activation function for each hidden layer.\n",
        "    The input layer is always 28*28 and the output layer is always 10 for this dataset.\n",
        "    '''\n",
        "    def __init__(self, topology, activations, include_dropout=False): #this initializes the structure of the network\n",
        "        super(MLP, self).__init__()\n",
        "        self.topology = topology\n",
        "        self.hidden_activations = activations\n",
        "        self.include_dropout = include_dropout\n",
        "\n",
        "        #Create layer topologies\n",
        "        for i in range(len(self.topology)-1):\n",
        "            setattr(self, 'fc' + str(i), nn.Linear(self.topology[i], self.topology[i+1]))\n",
        "            \n",
        "\n",
        "\n",
        "    def forward(self, x): #this modifies the elements of the intial structure defined above\n",
        "        x = x.view(-1, self.topology[0]) #the array is sent in as a vector\n",
        "\n",
        "        #Forward pass through hidden layers with activations\n",
        "        for i in range(len(self.topology)-2):\n",
        "            #randomly drop out 20% of the neurons in the first hidden layer\n",
        "            if(i==1 and self.include_dropout):\n",
        "                x = nn.Dropout(0.2)(x)\n",
        "            x = getattr(self, 'fc' + str(i))(x)\n",
        "            x = self.hidden_activations[i](x)\n",
        "\n",
        "        #Forward pass through output layer\n",
        "        return getattr(self, 'fc' + str(len(self.topology)-2))(x)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model and Optimizer Generators\n",
        "These two classes are used to iterate through a set of target topologies (number of layers, layer size, activations for each layer)\n",
        "and optimizers. For this project we've chose 3 different optimizers to test and these are \"hardcoded\" as selections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 515,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class RandomTestGenerator:\n",
        "    '''\n",
        "    Random model generator. Given a set of topologies, activations, and initializers,\n",
        "    this class can generate a model with random parameters.\n",
        "    Optimizer params are passed in as a dictionary. Only a few parameters are supported for each.\n",
        "    Each of the additional parameters should be passed as an array to be selected from.\n",
        "    'adam' : lr, weight_decay\n",
        "    'sgd' : lr, momentum, weight_decay\n",
        "    'asgd' : lr, weight_decay\n",
        "    '''\n",
        "    def __init__(self, topologies, optimizer_params):\n",
        "        self.topologies = topologies\n",
        "        self.optimizer_params = optimizer_params\n",
        "\n",
        "    def random_model(self):\n",
        "        '''\n",
        "        Generate a random model with the given topologies, activations, and initializers.\n",
        "        '''\n",
        "        selected_topology = self.topologies[torch.randint(len(self.topologies), (1,)).item()]\n",
        "        model = MLP(selected_topology[0], selected_topology[1], False)\n",
        "        return model, selected_topology[0], selected_topology[1]\n",
        "    \n",
        "\n",
        "    def random_optimizer(self, model):\n",
        "        '''\n",
        "        Generate a random optimizer for the given model.\n",
        "        '''\n",
        "\n",
        "        algorithm_selector = torch.randint(3, (1,)).item()\n",
        "\n",
        "        optimizer_params = {}\n",
        "        optimizer_algo = None\n",
        "\n",
        "        if algorithm_selector == 0:\n",
        "            lr = self.optimizer_params['adam']['lr'][torch.randint(len(self.optimizer_params['adam']['lr']), (1,)).item()]\n",
        "            wd = self.optimizer_params['adam']['weight_decay'][torch.randint(len(self.optimizer_params['adam']['weight_decay']), (1,)).item()]\n",
        "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "            optimizer_params['lr'] = lr\n",
        "            optimizer_params['weight_decay'] = wd\n",
        "            optimizer_algo = 'adam'\n",
        "        elif algorithm_selector == 1:\n",
        "            lr = self.optimizer_params['sgd']['lr'][torch.randint(len(self.optimizer_params['sgd']['lr']), (1,)).item()]\n",
        "            momentum = self.optimizer_params['sgd']['momentum'][torch.randint(len(self.optimizer_params['sgd']['momentum']), (1,)).item()]\n",
        "            wd = self.optimizer_params['sgd']['weight_decay'][torch.randint(len(self.optimizer_params['sgd']['weight_decay']), (1,)).item()]\n",
        "            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
        "            optimizer_params['lr'] = lr\n",
        "            optimizer_params['momentum'] = momentum\n",
        "            optimizer_params['weight_decay'] = wd\n",
        "            optimizer_algo = 'sgd'\n",
        "        elif algorithm_selector == 2:\n",
        "            lr = self.optimizer_params['asgd']['lr'][torch.randint(len(self.optimizer_params['asgd']['lr']), (1,)).item()]\n",
        "            wd = self.optimizer_params['asgd']['weight_decay'][torch.randint(len(self.optimizer_params['asgd']['weight_decay']), (1,)).item()]\n",
        "            optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=wd)\n",
        "            optimizer_params['lr'] = lr\n",
        "            optimizer_params['weight_decay'] = wd\n",
        "            optimizer_algo = 'asgd'\n",
        "        return optimizer, optimizer_algo, optimizer_params\n",
        "    \n",
        "\n",
        "class SequentialTestGenerator:\n",
        "    '''\n",
        "    Random model generator. Given a set of topologies, activations, and initializers,\n",
        "    this class can generate a model with random parameters.\n",
        "    Optimizer params are passed in as a dictionary. Only a few parameters are supported for each.\n",
        "    Each of the additional parameters should be passed as an array to be selected from.\n",
        "    'adam' : lr, weight_decay\n",
        "    'sgd' : lr, momentum, weight_decay\n",
        "    'asgd' : lr, weight_decay\n",
        "    '''\n",
        "    def __init__(self, topologies, optimizer_params):\n",
        "        self.topologies = topologies\n",
        "        self.optimizer_params = optimizer_params\n",
        "\n",
        "        self.topology_index = 0\n",
        "        self.optimizer_algo_index = 0\n",
        "        self.optimizer_params_index = [0, 0, 0]\n",
        "\n",
        "    def next_model(self):\n",
        "        '''\n",
        "        Generate a model based on the current iterator parameters.\n",
        "        '''\n",
        "        if self.topology_index >= len(self.topologies):\n",
        "            return None, None, None\n",
        "\n",
        "        topology = self.topologies[self.topology_index]\n",
        "\n",
        "        model = MLP(topology[0], topology[1], False)\n",
        "\n",
        "        return model, topology[0], topology[1]\n",
        "    \n",
        "    def iterate_model(self):\n",
        "        '''\n",
        "        Generate the next model in the list of topologies and activations.\n",
        "        '''\n",
        "        self.topology_index += 1\n",
        "\n",
        "    def has_next_model(self):\n",
        "        return self.topology_index < len(self.topologies)\n",
        "\n",
        "    def reset_model_iterator(self):\n",
        "        '''\n",
        "        Reset the model iterator to the beginning.\n",
        "        '''\n",
        "        self.topology_index = 0\n",
        " \n",
        "    def reset_optimizer(self):\n",
        "        '''\n",
        "        Reset the optimizer iterator to the beginning.\n",
        "        '''\n",
        "        self.optimizer_algo_index = 0\n",
        "        self.optimizer_params_index = [0, 0, 0]\n",
        "\n",
        "    def iterate_optimizer(self):\n",
        "        '''\n",
        "        Generate the next optimizer in the list of optimizer parameters.\n",
        "        '''\n",
        "        if self.optimizer_algo_index == 0:\n",
        "            optimizer_algo = 'adam'\n",
        "        elif self.optimizer_algo_index == 1:\n",
        "            optimizer_algo = 'sgd'\n",
        "        elif self.optimizer_algo_index >= 2:\n",
        "            optimizer_algo = 'asgd'\n",
        "\n",
        "        self.optimizer_params_index[0] += 1\n",
        "        if self.optimizer_params_index[0] >= len(self.optimizer_params[optimizer_algo]['lr']):\n",
        "            self.optimizer_params_index[0] = 0\n",
        "            self.optimizer_params_index[1] += 1\n",
        "            if self.optimizer_params_index[1] >= len(self.optimizer_params[optimizer_algo]['weight_decay']):\n",
        "                self.optimizer_params_index[1] = 0\n",
        "                self.optimizer_params_index[2] += 1\n",
        "                if(optimizer_algo == 'sgd'):\n",
        "                    if self.optimizer_params_index[2] >= len(self.optimizer_params[optimizer_algo]['momentum']):\n",
        "                        self.optimizer_params_index[2] = 0\n",
        "                        self.optimizer_algo_index += 1\n",
        "                else:\n",
        "                    self.optimizer_algo_index += 1\n",
        "\n",
        "    def has_next_optimizer(self):\n",
        "        return self.optimizer_algo_index < len(self.optimizer_params)\n",
        "    \n",
        "    def next_optimizer(self, model):\n",
        "        '''\n",
        "        Generate the next optimizer in the list of optimizer parameters.\n",
        "        '''\n",
        "        optimizer_params = {}\n",
        "        optimizer_algo = None\n",
        "\n",
        "        if self.optimizer_algo_index >= len(self.optimizer_params):\n",
        "            return None, None, None\n",
        "\n",
        "        if self.optimizer_algo_index == 0:\n",
        "            lr = self.optimizer_params['adam']['lr'][self.optimizer_params_index[0]]\n",
        "            wd = self.optimizer_params['adam']['weight_decay'][self.optimizer_params_index[1]]\n",
        "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "            optimizer_params['lr'] = lr\n",
        "            optimizer_params['weight_decay'] = wd\n",
        "            optimizer_algo = 'adam'\n",
        "        elif self.optimizer_algo_index == 1:\n",
        "            lr = self.optimizer_params['sgd']['lr'][self.optimizer_params_index[0]]\n",
        "            wd = self.optimizer_params['sgd']['weight_decay'][self.optimizer_params_index[1]]\n",
        "            momentum = self.optimizer_params['sgd']['momentum'][self.optimizer_params_index[2]]\n",
        "            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=wd)\n",
        "            optimizer_params['lr'] = lr\n",
        "            optimizer_params['momentum'] = momentum\n",
        "            optimizer_params['weight_decay'] = wd\n",
        "            optimizer_algo = 'sgd'\n",
        "        elif self.optimizer_algo_index == 2:\n",
        "            lr = self.optimizer_params['asgd']['lr'][self.optimizer_params_index[0]]\n",
        "            wd = self.optimizer_params['asgd']['weight_decay'][self.optimizer_params_index[1]]\n",
        "            optimizer = optim.ASGD(model.parameters(), lr=lr, weight_decay=wd)\n",
        "            optimizer_params['lr'] = lr\n",
        "            optimizer_params['weight_decay'] = wd\n",
        "            optimizer_algo = 'asgd'\n",
        "        \n",
        "        return optimizer, optimizer_algo, optimizer_params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Runner Implementations\n",
        "run_evaluation executes a single model and optimizer, for a given number of epochs over a set of training and test data.\n",
        "The other parameters are there for reporting purposes.\n",
        "\n",
        "iterate_generator loops through the passed topology and optimizer configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 516,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def run_evaluation(model, optimizer, criterion, num_epochs, train_data_loader, test_data_loader, topology, activations, algo, params, output_file):\n",
        "        #Get the model and optimizer for this run\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(train_data_loader, 0):\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                # if i % 100 == 99:  # print every 100 mini-batches\n",
        "                #     print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "                #     running_loss = 0.0\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_data_loader:\n",
        "                images, labels = data\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        activation_string = '['\n",
        "        for activation in activations:\n",
        "            activation_string += activation.__name__ + ', '\n",
        "\n",
        "        activation_string = activation_string[:-2] + ']'\n",
        "\n",
        "        print('Accuracy:  %d %%' % (100 * correct / total))\n",
        "        print('Topology:', topology)\n",
        "        print('Activations:', activation_string)\n",
        "        print('Optimizer:', algo)\n",
        "        print('Params:', params)\n",
        "\n",
        "        results_file = open(output_file, 'a')\n",
        "        results_file.write(str(100 * correct / total) + ',' + str(topology) + ',' + activation_string + ',' + algo + ',' + str(params) + '\\n')\n",
        "        results_file.close()\n",
        "\n",
        "\n",
        "def iterate_generator(output_file, generator, epochs_per_run, train_data_loader, test_data_loader, criterion):\n",
        "    #initialize model and optimizer so they are not None\n",
        "    model, optimizer = True, True\n",
        "\n",
        "    while generator.has_next_model():\n",
        "        generator.reset_optimizer()\n",
        "\n",
        "        while generator.has_next_optimizer():\n",
        "            #Get the current iterator model and optimizer\n",
        "            model, iter_topology, iter_activations = generator.next_model()\n",
        "            optimizer, iter_algo, iter_params = generator.next_optimizer(model)\n",
        "\n",
        "            #Run the evaluation\n",
        "            run_evaluation(model, optimizer, criterion, epochs_per_run, train_data_loader, test_data_loader, iter_topology, iter_activations, iter_algo, iter_params, output_file)\n",
        "\n",
        "            #Iterate to the next optimizer\n",
        "            generator.iterate_optimizer()\n",
        "\n",
        "        generator.iterate_model() #move to the next model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 517,
      "metadata": {
        "id": "YDg8ZzyzSKpu"
      },
      "outputs": [],
      "source": [
        "# Transformations --> this is a \"pre-processing step\" that's typical for image processing methods\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize data to range [-1, 1]\n",
        "])\n",
        "# This dataset is already \"sorted\" as part of the import method, but no \"validation\" set has been selected in this case\n",
        "# Loading the FashionMNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Training and Testing loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 518,
      "metadata": {
        "id": "3DRu0tGPS0dy"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset -- later we'll see that this using the \"keras to_categorical\" method as discussed in class\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 519,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "DnFh3_pTS8fD",
        "outputId": "5dc06071-596f-47f2-90e9-846eca184a30"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#This cell is designed to display a few images from the dataset\n",
        "#It isn't necessary to run this, but it can help give a better idea of the challanges your model will face\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Displaying figures from the dataset randomly\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 520,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfpEh_TyTLBa",
        "outputId": "bd6acb53-37dd-446b-a37b-3e856476f51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.9382597017288208\n",
            "Epoch 1, Batch 200, Loss: 1.2726190328598022\n",
            "Epoch 1, Batch 300, Loss: 0.8514104473590851\n",
            "Epoch 1, Batch 400, Loss: 0.631805791258812\n",
            "Epoch 1, Batch 500, Loss: 0.511779689192772\n",
            "Epoch 1, Batch 600, Loss: 0.4571631535887718\n",
            "Epoch 1, Batch 700, Loss: 0.396083063185215\n",
            "Epoch 1, Batch 800, Loss: 0.36767498061060905\n",
            "Epoch 1, Batch 900, Loss: 0.348691092133522\n",
            "Epoch 2, Batch 100, Loss: 0.324303784519434\n",
            "Epoch 2, Batch 200, Loss: 0.30306769758462904\n",
            "Epoch 2, Batch 300, Loss: 0.28224260970950127\n",
            "Epoch 2, Batch 400, Loss: 0.2811019948869944\n",
            "Epoch 2, Batch 500, Loss: 0.29171850070357325\n",
            "Epoch 2, Batch 600, Loss: 0.2778995803743601\n",
            "Epoch 2, Batch 700, Loss: 0.27258835718035695\n",
            "Epoch 2, Batch 800, Loss: 0.2437984708696604\n",
            "Epoch 2, Batch 900, Loss: 0.2319589452445507\n",
            "Accuracy:  92 %\n",
            "Topology: [784, 32, 16, 10]\n",
            "Activations: [sigmoid, tanh]\n",
            "Optimizer: adam\n",
            "Params: {'lr': 0.001, 'weight_decay': 0.0}\n",
            "Epoch 1, Batch 100, Loss: 1.664015872478485\n",
            "Epoch 1, Batch 200, Loss: 0.7651946783065796\n",
            "Epoch 1, Batch 300, Loss: 0.5157528284192086\n",
            "Epoch 1, Batch 400, Loss: 0.39063491821289065\n",
            "Epoch 1, Batch 500, Loss: 0.3764733698964119\n",
            "Epoch 1, Batch 600, Loss: 0.3398798841238022\n",
            "Epoch 1, Batch 700, Loss: 0.3132279358804226\n",
            "Epoch 1, Batch 800, Loss: 0.2995660588145256\n",
            "Epoch 1, Batch 900, Loss: 0.29170434176921844\n",
            "Epoch 2, Batch 100, Loss: 0.2441463989764452\n",
            "Epoch 2, Batch 200, Loss: 0.24758148863911628\n",
            "Epoch 2, Batch 300, Loss: 0.25165904335677625\n",
            "Epoch 2, Batch 400, Loss: 0.2505770164728165\n",
            "Epoch 2, Batch 500, Loss: 0.261052685379982\n",
            "Epoch 2, Batch 600, Loss: 0.24813669256865978\n",
            "Epoch 2, Batch 700, Loss: 0.22280128479003905\n",
            "Epoch 2, Batch 800, Loss: 0.2299598551914096\n",
            "Epoch 2, Batch 900, Loss: 0.19878946907818318\n",
            "Accuracy:  93 %\n",
            "Topology: [784, 32, 16, 10]\n",
            "Activations: [sigmoid, tanh]\n",
            "Optimizer: adam\n",
            "Params: {'lr': 0.002, 'weight_decay': 0.0}\n",
            "Epoch 1, Batch 100, Loss: 1.5260559445619584\n",
            "Epoch 1, Batch 200, Loss: 0.6827572774887085\n",
            "Epoch 1, Batch 300, Loss: 0.4770061609148979\n",
            "Epoch 1, Batch 400, Loss: 0.4033819644153118\n",
            "Epoch 1, Batch 500, Loss: 0.3835370352864265\n",
            "Epoch 1, Batch 600, Loss: 0.3734411898255348\n",
            "Epoch 1, Batch 700, Loss: 0.32952660486102103\n",
            "Epoch 1, Batch 800, Loss: 0.3507539834082127\n",
            "Epoch 1, Batch 900, Loss: 0.3218620082736015\n",
            "Epoch 2, Batch 100, Loss: 0.3149944902956486\n",
            "Epoch 2, Batch 200, Loss: 0.30311828829348086\n",
            "Epoch 2, Batch 300, Loss: 0.2972600232809782\n",
            "Epoch 2, Batch 400, Loss: 0.2871989821642637\n",
            "Epoch 2, Batch 500, Loss: 0.26703827783465384\n",
            "Epoch 2, Batch 600, Loss: 0.29289122320711614\n",
            "Epoch 2, Batch 700, Loss: 0.2646146212518215\n",
            "Epoch 2, Batch 800, Loss: 0.27339421793818475\n",
            "Epoch 2, Batch 900, Loss: 0.26398514315485955\n",
            "Accuracy:  92 %\n",
            "Topology: [784, 32, 16, 10]\n",
            "Activations: [sigmoid, tanh]\n",
            "Optimizer: adam\n",
            "Params: {'lr': 0.004, 'weight_decay': 0.0}\n",
            "Epoch 1, Batch 100, Loss: 1.2303267121315002\n",
            "Epoch 1, Batch 200, Loss: 0.6029175519943237\n",
            "Epoch 1, Batch 300, Loss: 0.479310392588377\n",
            "Epoch 1, Batch 400, Loss: 0.43512205213308336\n",
            "Epoch 1, Batch 500, Loss: 0.3976284791529179\n",
            "Epoch 1, Batch 600, Loss: 0.445089261084795\n",
            "Epoch 1, Batch 700, Loss: 0.44219100520014765\n",
            "Epoch 1, Batch 800, Loss: 0.3966787479817867\n",
            "Epoch 1, Batch 900, Loss: 0.362500776052475\n",
            "Epoch 2, Batch 100, Loss: 0.39308875665068627\n",
            "Epoch 2, Batch 200, Loss: 0.40135866567492484\n",
            "Epoch 2, Batch 300, Loss: 0.3693964061141014\n",
            "Epoch 2, Batch 400, Loss: 0.3448367880284786\n",
            "Epoch 2, Batch 500, Loss: 0.328584872931242\n",
            "Epoch 2, Batch 600, Loss: 0.38312754541635513\n",
            "Epoch 2, Batch 700, Loss: 0.3336847570538521\n",
            "Epoch 2, Batch 800, Loss: 0.35237405851483344\n",
            "Epoch 2, Batch 900, Loss: 0.35619110472500326\n",
            "Accuracy:  91 %\n",
            "Topology: [784, 32, 16, 10]\n",
            "Activations: [sigmoid, tanh]\n",
            "Optimizer: adam\n",
            "Params: {'lr': 0.008, 'weight_decay': 0.0}\n",
            "Epoch 1, Batch 100, Loss: 1.5369697469472885\n",
            "Epoch 1, Batch 200, Loss: 0.8830454105138779\n",
            "Epoch 1, Batch 300, Loss: 0.7099759531021118\n",
            "Epoch 1, Batch 400, Loss: 0.6915759506821633\n",
            "Epoch 1, Batch 500, Loss: 0.6346835285425186\n",
            "Epoch 1, Batch 600, Loss: 0.6091158258914947\n",
            "Epoch 1, Batch 700, Loss: 0.6128880614042282\n",
            "Epoch 1, Batch 800, Loss: 0.587276295721531\n",
            "Epoch 1, Batch 900, Loss: 0.5470508298277855\n",
            "Epoch 2, Batch 100, Loss: 0.5560135415196419\n",
            "Epoch 2, Batch 200, Loss: 0.5799067151546479\n",
            "Epoch 2, Batch 300, Loss: 0.5482788649201393\n",
            "Epoch 2, Batch 400, Loss: 0.5813635575771332\n",
            "Epoch 2, Batch 500, Loss: 0.5770347875356674\n",
            "Epoch 2, Batch 600, Loss: 0.5563613373041153\n",
            "Epoch 2, Batch 700, Loss: 0.5487619709968566\n",
            "Epoch 2, Batch 800, Loss: 0.5015646322071552\n",
            "Epoch 2, Batch 900, Loss: 0.5139183710515499\n",
            "Accuracy:  84 %\n",
            "Topology: [784, 32, 16, 10]\n",
            "Activations: [sigmoid, tanh]\n",
            "Optimizer: adam\n",
            "Params: {'lr': 0.01, 'weight_decay': 0.0}\n",
            "Epoch 1, Batch 100, Loss: 1.7824126386642456\n",
            "Epoch 1, Batch 200, Loss: 1.1986960011720658\n",
            "Epoch 1, Batch 300, Loss: 1.1601324772834778\n",
            "Epoch 1, Batch 400, Loss: 1.1268978744745255\n",
            "Epoch 1, Batch 500, Loss: 1.1815487599372865\n",
            "Epoch 1, Batch 600, Loss: 1.0943067663908004\n",
            "Epoch 1, Batch 700, Loss: 1.1163831806182862\n",
            "Epoch 1, Batch 800, Loss: 1.0909939205646515\n",
            "Epoch 1, Batch 900, Loss: 1.0913421934843064\n",
            "Epoch 2, Batch 100, Loss: 1.0942070746421815\n",
            "Epoch 2, Batch 200, Loss: 1.110347604751587\n",
            "Epoch 2, Batch 300, Loss: 1.0407159864902495\n",
            "Epoch 2, Batch 400, Loss: 1.1204942005872727\n",
            "Epoch 2, Batch 500, Loss: 1.0745877039432525\n",
            "Epoch 2, Batch 600, Loss: 1.0914750224351883\n",
            "Epoch 2, Batch 700, Loss: 1.0782464689016342\n",
            "Epoch 2, Batch 800, Loss: 1.089687460064888\n",
            "Epoch 2, Batch 900, Loss: 1.0872495448589325\n",
            "Accuracy:  65 %\n",
            "Topology: [784, 32, 16, 10]\n",
            "Activations: [sigmoid, tanh]\n",
            "Optimizer: adam\n",
            "Params: {'lr': 0.02, 'weight_decay': 0.0}\n",
            "Epoch 1, Batch 100, Loss: 1.6745633006095886\n",
            "Epoch 1, Batch 200, Loss: 0.8114246821403504\n",
            "Epoch 1, Batch 300, Loss: 0.5480451774597168\n",
            "Epoch 1, Batch 400, Loss: 0.4258572354912758\n",
            "Epoch 1, Batch 500, Loss: 0.3805307957530022\n",
            "Epoch 1, Batch 600, Loss: 0.35241480872035025\n",
            "Epoch 1, Batch 700, Loss: 0.31817486077547075\n",
            "Epoch 1, Batch 800, Loss: 0.31092887863516805\n",
            "Epoch 1, Batch 900, Loss: 0.283730009496212\n",
            "Epoch 2, Batch 100, Loss: 0.2493848342448473\n",
            "Epoch 2, Batch 200, Loss: 0.2710148863494396\n",
            "Epoch 2, Batch 300, Loss: 0.24791443213820458\n",
            "Epoch 2, Batch 400, Loss: 0.23354551315307617\n",
            "Epoch 2, Batch 500, Loss: 0.24711202397942544\n",
            "Epoch 2, Batch 600, Loss: 0.21574540346860885\n",
            "Epoch 2, Batch 700, Loss: 0.2157524325698614\n",
            "Epoch 2, Batch 800, Loss: 0.20296908892691135\n",
            "Epoch 2, Batch 900, Loss: 0.2217888980358839\n",
            "Epoch 3, Batch 100, Loss: 0.18960539776831864\n",
            "Epoch 3, Batch 200, Loss: 0.19071287259459496\n",
            "Epoch 3, Batch 300, Loss: 0.17635198788717388\n",
            "Epoch 3, Batch 400, Loss: 0.19485379602760078\n",
            "Epoch 3, Batch 500, Loss: 0.18563243467360735\n",
            "Epoch 3, Batch 600, Loss: 0.18906497078016402\n",
            "Epoch 3, Batch 700, Loss: 0.19022795595228673\n",
            "Epoch 3, Batch 800, Loss: 0.18803133945912123\n",
            "Epoch 3, Batch 900, Loss: 0.18210889127105476\n",
            "Epoch 4, Batch 100, Loss: 0.16432898484170436\n",
            "Epoch 4, Batch 200, Loss: 0.17078831627964974\n",
            "Epoch 4, Batch 300, Loss: 0.18195123622193932\n",
            "Epoch 4, Batch 400, Loss: 0.16956737289205193\n",
            "Epoch 4, Batch 500, Loss: 0.16428275706246495\n",
            "Epoch 4, Batch 600, Loss: 0.16588079053908586\n",
            "Epoch 4, Batch 700, Loss: 0.1658291372656822\n",
            "Epoch 4, Batch 800, Loss: 0.15328412052243948\n",
            "Epoch 4, Batch 900, Loss: 0.17117537200450897\n",
            "Epoch 5, Batch 100, Loss: 0.1417254194431007\n",
            "Epoch 5, Batch 200, Loss: 0.14360914336517452\n",
            "Epoch 5, Batch 300, Loss: 0.14914622031152247\n",
            "Epoch 5, Batch 400, Loss: 0.16455358177423476\n",
            "Epoch 5, Batch 500, Loss: 0.1476514857634902\n",
            "Epoch 5, Batch 600, Loss: 0.13855583289638163\n",
            "Epoch 5, Batch 700, Loss: 0.145793032720685\n",
            "Epoch 5, Batch 800, Loss: 0.1529908748716116\n",
            "Epoch 5, Batch 900, Loss: 0.16361024901270865\n",
            "Epoch 6, Batch 100, Loss: 0.1268345218151808\n",
            "Epoch 6, Batch 200, Loss: 0.15035626104101538\n",
            "Epoch 6, Batch 300, Loss: 0.14945959407836198\n",
            "Epoch 6, Batch 400, Loss: 0.15348164970055223\n",
            "Epoch 6, Batch 500, Loss: 0.14799221407622098\n",
            "Epoch 6, Batch 600, Loss: 0.1365360912680626\n",
            "Epoch 6, Batch 700, Loss: 0.1376292436942458\n",
            "Epoch 6, Batch 800, Loss: 0.1338525833375752\n",
            "Epoch 6, Batch 900, Loss: 0.13754947926849126\n",
            "Epoch 7, Batch 100, Loss: 0.12186634059995413\n",
            "Epoch 7, Batch 200, Loss: 0.14429735170677305\n",
            "Epoch 7, Batch 300, Loss: 0.1404129553027451\n",
            "Epoch 7, Batch 400, Loss: 0.14062925716862082\n",
            "Epoch 7, Batch 500, Loss: 0.12922497636638583\n",
            "Epoch 7, Batch 600, Loss: 0.1476320748217404\n",
            "Epoch 7, Batch 700, Loss: 0.1240609486028552\n",
            "Epoch 7, Batch 800, Loss: 0.11870353977195919\n",
            "Epoch 7, Batch 900, Loss: 0.1229447160102427\n",
            "Epoch 8, Batch 100, Loss: 0.12576037986204028\n",
            "Epoch 8, Batch 200, Loss: 0.12931220008060337\n",
            "Epoch 8, Batch 300, Loss: 0.12962249235250056\n",
            "Epoch 8, Batch 400, Loss: 0.1134462061431259\n",
            "Epoch 8, Batch 500, Loss: 0.12623501888476313\n",
            "Epoch 8, Batch 600, Loss: 0.13124170884490013\n",
            "Epoch 8, Batch 700, Loss: 0.13652594028040765\n",
            "Epoch 8, Batch 800, Loss: 0.11569879850372672\n",
            "Epoch 8, Batch 900, Loss: 0.12398248828947545\n",
            "Epoch 9, Batch 100, Loss: 0.11258358928374947\n",
            "Epoch 9, Batch 200, Loss: 0.1179048733599484\n",
            "Epoch 9, Batch 300, Loss: 0.13271287743002178\n",
            "Epoch 9, Batch 400, Loss: 0.11762960011139512\n",
            "Epoch 9, Batch 500, Loss: 0.1243590284883976\n",
            "Epoch 9, Batch 600, Loss: 0.13163304867222905\n",
            "Epoch 9, Batch 700, Loss: 0.11374370232224465\n",
            "Epoch 9, Batch 800, Loss: 0.12150972472503781\n",
            "Epoch 9, Batch 900, Loss: 0.1231715351715684\n",
            "Epoch 10, Batch 100, Loss: 0.09617270717397332\n",
            "Epoch 10, Batch 200, Loss: 0.12207994148135186\n",
            "Epoch 10, Batch 300, Loss: 0.12386939763091505\n",
            "Epoch 10, Batch 400, Loss: 0.1255627774260938\n",
            "Epoch 10, Batch 500, Loss: 0.11282440407201648\n",
            "Epoch 10, Batch 600, Loss: 0.12511315997689962\n",
            "Epoch 10, Batch 700, Loss: 0.09838629411533475\n",
            "Epoch 10, Batch 800, Loss: 0.11060235598124564\n",
            "Epoch 10, Batch 900, Loss: 0.1264448099397123\n",
            "Accuracy:  95 %\n",
            "Topology: [784, 32, 16, 10]\n",
            "Activations: [sigmoid, tanh]\n",
            "Optimizer: adam\n",
            "Params: {'lr': 0.002, 'weight_decay': 0.0}\n",
            "Epoch 1, Batch 100, Loss: 1.9297627210617065\n",
            "Epoch 1, Batch 200, Loss: 1.671589777469635\n",
            "Epoch 1, Batch 300, Loss: 1.6585070729255675\n",
            "Epoch 1, Batch 400, Loss: 1.6013359725475311\n",
            "Epoch 1, Batch 500, Loss: 1.5743433809280396\n",
            "Epoch 1, Batch 600, Loss: 1.5884771239757538\n",
            "Epoch 1, Batch 700, Loss: 1.5499559330940247\n",
            "Epoch 1, Batch 800, Loss: 1.5516600108146668\n",
            "Epoch 1, Batch 900, Loss: 1.5314679563045501\n",
            "Epoch 2, Batch 100, Loss: 1.5457052886486053\n",
            "Epoch 2, Batch 200, Loss: 1.5290467202663423\n",
            "Epoch 2, Batch 300, Loss: 1.4902660036087036\n",
            "Epoch 2, Batch 400, Loss: 1.557258154153824\n",
            "Epoch 2, Batch 500, Loss: 1.495813845396042\n",
            "Epoch 2, Batch 600, Loss: 1.5012386178970336\n",
            "Epoch 2, Batch 700, Loss: 1.4966299724578858\n",
            "Epoch 2, Batch 800, Loss: 1.5528558659553529\n",
            "Epoch 2, Batch 900, Loss: 1.5160025930404664\n",
            "Epoch 3, Batch 100, Loss: 1.5133940041065217\n",
            "Epoch 3, Batch 200, Loss: 1.504903930425644\n",
            "Epoch 3, Batch 300, Loss: 1.4968306970596315\n",
            "Epoch 3, Batch 400, Loss: 1.4886456251144409\n",
            "Epoch 3, Batch 500, Loss: 1.4814799582958222\n",
            "Epoch 3, Batch 600, Loss: 1.519817010164261\n",
            "Epoch 3, Batch 700, Loss: 1.5154687821865083\n",
            "Epoch 3, Batch 800, Loss: 1.5397957408428191\n",
            "Epoch 3, Batch 900, Loss: 1.4814865803718567\n",
            "Epoch 4, Batch 100, Loss: 1.5186401748657226\n",
            "Epoch 4, Batch 200, Loss: 1.5275802958011626\n",
            "Epoch 4, Batch 300, Loss: 1.4911020994186401\n",
            "Epoch 4, Batch 400, Loss: 1.501115196943283\n",
            "Epoch 4, Batch 500, Loss: 1.5358070015907288\n",
            "Epoch 4, Batch 600, Loss: 1.5452467179298401\n",
            "Epoch 4, Batch 700, Loss: 1.5015770018100738\n",
            "Epoch 4, Batch 800, Loss: 1.5459739661216736\n",
            "Epoch 4, Batch 900, Loss: 1.515214649438858\n",
            "Epoch 5, Batch 100, Loss: 1.484386341571808\n",
            "Epoch 5, Batch 200, Loss: 1.4954304790496826\n",
            "Epoch 5, Batch 300, Loss: 1.5247734522819518\n",
            "Epoch 5, Batch 400, Loss: 1.5346690225601196\n",
            "Epoch 5, Batch 500, Loss: 1.5059738385677337\n",
            "Epoch 5, Batch 600, Loss: 1.516772518157959\n",
            "Epoch 5, Batch 700, Loss: 1.5291590642929078\n",
            "Epoch 5, Batch 800, Loss: 1.4954053139686585\n",
            "Epoch 5, Batch 900, Loss: 1.4879118406772613\n",
            "Epoch 6, Batch 100, Loss: 1.5080528342723847\n",
            "Epoch 6, Batch 200, Loss: 1.4923902094364165\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[520], line 33\u001b[0m\n\u001b[1;32m     10\u001b[0m iterate_generator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,lr_eval,\u001b[38;5;241m2\u001b[39m, train_loader, test_loader, nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss())\n\u001b[1;32m     12\u001b[0m generator \u001b[38;5;241m=\u001b[39m SequentialTestGenerator(\n\u001b[1;32m     13\u001b[0m     topologies\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m#two layer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     }\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[43miterate_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# nn.CrossEntropyLoss()\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[516], line 59\u001b[0m, in \u001b[0;36miterate_generator\u001b[0;34m(output_file, generator, epochs_per_run, train_data_loader, test_data_loader, criterion)\u001b[0m\n\u001b[1;32m     56\u001b[0m optimizer, iter_algo, iter_params \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mnext_optimizer(model)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#Run the evaluation\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_per_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_topology\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_activations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_algo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#Iterate to the next optimizer\u001b[39;00m\n\u001b[1;32m     62\u001b[0m generator\u001b[38;5;241m.\u001b[39miterate_optimizer()\n",
            "Cell \u001b[0;32mIn[516], line 6\u001b[0m, in \u001b[0;36mrun_evaluation\u001b[0;34m(model, optimizer, criterion, num_epochs, train_data_loader, test_data_loader, topology, activations, algo, params, output_file)\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      7\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/torchvision/datasets/mnist.py:143\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/PIL/Image.py:3269\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3267\u001b[0m shape \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3268\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[0;32m-> 3269\u001b[0m strides \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3271\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lr_eval = SequentialTestGenerator(\n",
        "    topologies=[\n",
        "        [[784,32,16,10],[torch.sigmoid, torch.tanh]]\n",
        "    ],\n",
        "    optimizer_params={\n",
        "        'adam': {'lr': [0.001,0.002,0.004,0.008,0.01,0.02], 'weight_decay': [0.0]},\n",
        "    }\n",
        ")\n",
        "\n",
        "iterate_generator('lr.csv',lr_eval,50, train_loader, test_loader, nn.CrossEntropyLoss())\n",
        "\n",
        "generator = SequentialTestGenerator(\n",
        "    topologies=[\n",
        "        #two layer\n",
        "        [[784, 32, 16, 10],[torch.sigmoid, torch.tanh]],\n",
        "        [[784, 32, 16, 10],[torch.sigmoid, torch.relu]],\n",
        "        [[784, 28, 28, 10],[torch.sigmoid, torch.tanh]],\n",
        "        [[784, 28, 28, 10],[torch.sigmoid, torch.relu]],\n",
        "        [[784, 64, 32, 10],[torch.sigmoid, torch.tanh]],\n",
        "        [[784, 64, 32, 10],[torch.sigmoid, torch.relu]],\n",
        "        #three layer\n",
        "        [[784, 64, 32, 16, 10],[torch.sigmoid, torch.sigmoid, torch.tanh]],\n",
        "        [[784, 64, 32, 16, 10],[torch.relu, torch.sigmoid, torch.tanh]],\n",
        "        [[784, 28, 28, 28, 10],[torch.sigmoid, torch.sigmoid, torch.tanh]],\n",
        "        [[784, 28, 28, 28, 10],[torch.relu, torch.sigmoid, torch.tanh]],\n",
        "        #four layer\n",
        "        [[784, 64, 32, 16, 8, 10],[torch.sigmoid, torch.sigmoid, torch.tanh, torch.tanh]],\n",
        "        [[784, 64, 32, 16, 8, 10],[torch.relu, torch.sigmoid, torch.tanh, torch.tanh]],\n",
        "        [[784, 64, 32, 16, 8, 10],[torch.relu, torch.sigmoid, torch.tanh, torch.relu]],\n",
        "        [[784, 28, 28, 28, 28, 10],[torch.sigmoid, torch.sigmoid, torch.tanh, torch.tanh]],\n",
        "        [[784, 28, 28, 28, 28, 10],[torch.relu, torch.sigmoid, torch.tanh, torch.tanh]],\n",
        "        [[784, 28, 28, 28, 28, 10],[torch.relu, torch.sigmoid, torch.tanh, torch.relu]],\n",
        "    ],\n",
        "    optimizer_params={\n",
        "        'adam': {'lr': [0.002, 0.02], 'weight_decay': [0.0, 0.001]},\n",
        "        'sgd': {'lr': [0.001, 0.01], 'momentum': [0.5, 0.1], 'weight_decay': [0.0, 0.001]},\n",
        "        'asgd': {'lr': [0.01, 0.02], 'weight_decay': [0.0, 0.001]}\n",
        "    }\n",
        ")\n",
        "\n",
        "iterate_generator('results.csv', generator, 25, train_loader, test_loader, nn.CrossEntropyLoss())\n",
        "\n",
        "# nn.CrossEntropyLoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfYr_0XlT-Cb",
        "outputId": "e298b73f-543d-49a6-dbf5-b3c0099fae75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 92.55%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: { 100*(correct / total)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "kNM8-ijzUE9w",
        "outputId": "a07af0ed-e731-461f-d8c1-35750b29394c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_index = 27\n",
        "test_image, test_label = test_dataset[image_index]\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(test_image.unsqueeze(0))\n",
        "    _, predicted_label = torch.max(output, 1)\n",
        "\n",
        "test_image_numpy = test_image.squeeze().numpy()\n",
        "\n",
        "plt.imshow(test_image_numpy, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label.item()}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoypxOXgGjuC"
      },
      "source": [
        "Notes for Part 1\n",
        "\n",
        "1. Activation fucntion:\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))  # Change activation function here\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "2. loss function and optimizer\n",
        "\n",
        "model = Net()\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Change loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "3. ~adding a dropout layer\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "        self.dropout = torch.nn.Dropout(0.2)  # Add a Dropout layer here\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply Dropout\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "4. model configurations / epochs\n",
        "\n",
        "epochs = 10  # Change number of epochs\n",
        "for epoch in range(epochs):\n",
        "    # Training loop\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Training steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3IIK5kzHGH0"
      },
      "source": [
        "## Task - 2\n",
        "\n",
        "### PyTorch FC ANN FMNIST Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_aWMlQ33ByRO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jOCzfnBvB_bQ"
      },
      "outputs": [],
      "source": [
        "# Transformations --> this is a \"pre-processing step\" that's typical for image processing methods\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize data to range [-1, 1]\n",
        "])\n",
        "# This dataset is already \"sorted\" as part of the import method, but no \"validation\" set has been selected in this case\n",
        "# Loading the FashionMNIST dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Training and Testing loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jZk_FS9JCLOH"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset -- later we'll see that this using the \"keras to_categorical\" method as discussed in class\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "ykrRIGSdCMu5",
        "outputId": "a6737577-19d7-459e-aa83-ccebed56246c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#This cell is designed to display a few images from the dataset\n",
        "#It isn't necessary to run this, but it can help give a better idea of the challanges your model will face\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Displaying figures from the dataset randomly\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3JLJ0ZFCER5m"
      },
      "outputs": [],
      "source": [
        "#Here we define the model parameters -- the general strucutre as provided here will produce a fully connected network [28x28] --> 32 --> 16 --> 10\n",
        "class MLP(nn.Module): #MLP stands for \"Multi-Layer Perceptron\"\n",
        "    def __init__(self): #this initializes the structure of the network\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 32) ## First fully connected linear layer, 28*28 input features and 32 outputs\n",
        "        self.fc2 = nn.Linear(32 , 16) ## Second fully connected linear layer, 32 inputs and 16 outputs\n",
        "        self.fc3 = nn.Linear(16, 10) ## 10 output features because MNIST has 10 target classes\n",
        "\n",
        "    def forward(self, x): #this modifies the elements of the intial structure defined above\n",
        "        x = x.view(-1, 28 * 28) #the array is sent in as a vector\n",
        "        x = torch.sigmoid(self.fc1(x)) ## Applying sigmoid activation for the first layer\n",
        "        x = torch.tanh(self.fc2(x)) ## Applying tanh activation for the second layer\n",
        "        x = self.fc3(x) ## no modifications to the activation of the output layer\n",
        "        return x\n",
        "\n",
        "# Initializing the neural network\n",
        "model = MLP()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hFOEXCPEVTw",
        "outputId": "6c4d33e6-8624-4eae-d51b-7008e6826780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 100, Loss: 2.3076939606666564\n",
            "Epoch 1, Batch 200, Loss: 2.2964122533798217\n",
            "Epoch 1, Batch 300, Loss: 2.283242826461792\n",
            "Epoch 1, Batch 400, Loss: 2.2733342361450197\n",
            "Epoch 1, Batch 500, Loss: 2.260932538509369\n",
            "Epoch 1, Batch 600, Loss: 2.2505964970588686\n",
            "Epoch 1, Batch 700, Loss: 2.239789249897003\n",
            "Epoch 1, Batch 800, Loss: 2.226941957473755\n",
            "Epoch 1, Batch 900, Loss: 2.211233465671539\n",
            "Epoch 2, Batch 100, Loss: 2.190563213825226\n",
            "Epoch 2, Batch 200, Loss: 2.176533591747284\n",
            "Epoch 2, Batch 300, Loss: 2.1595369601249694\n",
            "Epoch 2, Batch 400, Loss: 2.1390220952033996\n",
            "Epoch 2, Batch 500, Loss: 2.1246925830841064\n",
            "Epoch 2, Batch 600, Loss: 2.1038536286354064\n",
            "Epoch 2, Batch 700, Loss: 2.082137269973755\n",
            "Epoch 2, Batch 800, Loss: 2.0612794518470765\n",
            "Epoch 2, Batch 900, Loss: 2.042286524772644\n",
            "Epoch 3, Batch 100, Loss: 2.0021821641921997\n",
            "Epoch 3, Batch 200, Loss: 1.9823235082626343\n",
            "Epoch 3, Batch 300, Loss: 1.9635089230537415\n",
            "Epoch 3, Batch 400, Loss: 1.9351388883590699\n",
            "Epoch 3, Batch 500, Loss: 1.8960629653930665\n",
            "Epoch 3, Batch 600, Loss: 1.8779389011859893\n",
            "Epoch 3, Batch 700, Loss: 1.8577709782123566\n",
            "Epoch 3, Batch 800, Loss: 1.831951322555542\n",
            "Epoch 3, Batch 900, Loss: 1.809152752161026\n",
            "Epoch 4, Batch 100, Loss: 1.775564694404602\n",
            "Epoch 4, Batch 200, Loss: 1.7517645466327667\n",
            "Epoch 4, Batch 300, Loss: 1.7307748794555664\n",
            "Epoch 4, Batch 400, Loss: 1.705103542804718\n",
            "Epoch 4, Batch 500, Loss: 1.688017382621765\n",
            "Epoch 4, Batch 600, Loss: 1.6638209569454192\n",
            "Epoch 4, Batch 700, Loss: 1.6550491559505462\n",
            "Epoch 4, Batch 800, Loss: 1.6286163318157196\n",
            "Epoch 4, Batch 900, Loss: 1.6137325847148896\n",
            "Epoch 5, Batch 100, Loss: 1.5913103723526\n",
            "Epoch 5, Batch 200, Loss: 1.5662185955047607\n",
            "Epoch 5, Batch 300, Loss: 1.5531344091892243\n",
            "Epoch 5, Batch 400, Loss: 1.5462597942352294\n",
            "Epoch 5, Batch 500, Loss: 1.5273258531093596\n",
            "Epoch 5, Batch 600, Loss: 1.5072660219669343\n",
            "Epoch 5, Batch 700, Loss: 1.4946460902690888\n",
            "Epoch 5, Batch 800, Loss: 1.478904435634613\n",
            "Epoch 5, Batch 900, Loss: 1.4691534054279327\n",
            "Epoch 6, Batch 100, Loss: 1.451450947523117\n",
            "Epoch 6, Batch 200, Loss: 1.4404398143291473\n",
            "Epoch 6, Batch 300, Loss: 1.4138830065727235\n",
            "Epoch 6, Batch 400, Loss: 1.4139169144630432\n",
            "Epoch 6, Batch 500, Loss: 1.3996974861621856\n",
            "Epoch 6, Batch 600, Loss: 1.3946517741680144\n",
            "Epoch 6, Batch 700, Loss: 1.3719034254550935\n",
            "Epoch 6, Batch 800, Loss: 1.3637009072303772\n",
            "Epoch 6, Batch 900, Loss: 1.3497490918636321\n",
            "Epoch 7, Batch 100, Loss: 1.3403599631786347\n",
            "Epoch 7, Batch 200, Loss: 1.3296659946441651\n",
            "Epoch 7, Batch 300, Loss: 1.3129628944396972\n",
            "Epoch 7, Batch 400, Loss: 1.3071974265575408\n",
            "Epoch 7, Batch 500, Loss: 1.300282496213913\n",
            "Epoch 7, Batch 600, Loss: 1.291931470632553\n",
            "Epoch 7, Batch 700, Loss: 1.277839721441269\n",
            "Epoch 7, Batch 800, Loss: 1.2581574380397798\n",
            "Epoch 7, Batch 900, Loss: 1.267788008451462\n",
            "Epoch 8, Batch 100, Loss: 1.2574964785575866\n",
            "Epoch 8, Batch 200, Loss: 1.2280636620521546\n",
            "Epoch 8, Batch 300, Loss: 1.2275899374485015\n",
            "Epoch 8, Batch 400, Loss: 1.2262526142597199\n",
            "Epoch 8, Batch 500, Loss: 1.2103733336925506\n",
            "Epoch 8, Batch 600, Loss: 1.216845862865448\n",
            "Epoch 8, Batch 700, Loss: 1.1956938576698304\n",
            "Epoch 8, Batch 800, Loss: 1.1875049471855164\n",
            "Epoch 8, Batch 900, Loss: 1.1772031939029695\n",
            "Epoch 9, Batch 100, Loss: 1.175100063085556\n",
            "Epoch 9, Batch 200, Loss: 1.1748727405071258\n",
            "Epoch 9, Batch 300, Loss: 1.1470557355880737\n",
            "Epoch 9, Batch 400, Loss: 1.1414942359924316\n",
            "Epoch 9, Batch 500, Loss: 1.1289411848783493\n",
            "Epoch 9, Batch 600, Loss: 1.1431044352054596\n",
            "Epoch 9, Batch 700, Loss: 1.1371096807718277\n",
            "Epoch 9, Batch 800, Loss: 1.1286362504959107\n",
            "Epoch 9, Batch 900, Loss: 1.1134078299999237\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
        "\n",
        "# Training the neural network\n",
        "num_epochs = 9\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNMCpk60EaXr",
        "outputId": "c8ffbf3e-bd21-4e29-8428-8405792a0d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 0.6207%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: { correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "J2GkmLeQEeZV",
        "outputId": "cb5bae66-d3d2-4163-deef-5828aad6b068"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_index = 27\n",
        "test_image, test_label = test_dataset[image_index]\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(test_image.unsqueeze(0))\n",
        "    _, predicted_label = torch.max(output, 1)\n",
        "\n",
        "test_image_numpy = test_image.squeeze().numpy()\n",
        "\n",
        "plt.imshow(test_image_numpy, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label.item()}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5nxrEoAHAUX"
      },
      "source": [
        "## PART - 3\n",
        "\n",
        "### FMNIST CNN Implimentation with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ccRJi8VXH3_O"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k41uN-aAIH6Y"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_MUVyZ5Iksr",
        "outputId": "fee20814-4805-46b6-9c2a-cea97192b605"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AEoqWEFz5Ms-"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_tkHuwEK7B",
        "outputId": "6914193e-b027-4100-ce9b-c27788c30802"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thomasjones/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2024-10-14 04:31:08.036516: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Ultra\n",
            "2024-10-14 04:31:08.036554: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 128.00 GB\n",
            "2024-10-14 04:31:08.036560: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 48.00 GB\n",
            "2024-10-14 04:31:08.036575: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-10-14 04:31:08.036587: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='sigmoid', input_shape=(28, 28, 1)),  # 16 filters (reduced), 3x3 kernel\n",
        "    MaxPooling2D(pool_size=(5, 5)),  # Max pooling with 2x2 pool size\n",
        "    # Flatten the output before passing to Dense layers\n",
        "    Flatten(),\n",
        "    Dense(64, activation='softmax'),  # Reduced from 128 to 64 units\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 units for classification\n",
        "])\n",
        "\n",
        "## change the architecture with CONV2D, Pooling, and Dense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nPfHtKytJd9Q"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 5\n",
        "batch_size = 48\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=SGD(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlPkc9auJkET",
        "outputId": "ed426026-a519-43d4-a811-039b74e7c7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-14 04:31:08.517806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.1028 - loss: 2.3025\n",
            "Epoch 2/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.1085 - loss: 2.3024\n",
            "Epoch 3/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.1058 - loss: 2.3023\n",
            "Epoch 4/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.1110 - loss: 2.3022\n",
            "Epoch 5/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.1178 - loss: 2.3021\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0961 - loss: 2.3019\n",
            "Test accuracy: 0.0997999981045723\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig5GXhcG5fy6",
        "outputId": "b41b841c-b2e6-4520-e664-518039d33b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.1254 - loss: 2.3019 - val_accuracy: 0.0948 - val_loss: 2.3018\n",
            "Epoch 2/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.1136 - loss: 2.3018 - val_accuracy: 0.0978 - val_loss: 2.3017\n",
            "Epoch 3/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.1152 - loss: 2.3017 - val_accuracy: 0.0958 - val_loss: 2.3016\n",
            "Epoch 4/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.1226 - loss: 2.3015 - val_accuracy: 0.1462 - val_loss: 2.3015\n",
            "Epoch 5/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.1231 - loss: 2.3013 - val_accuracy: 0.0965 - val_loss: 2.3012\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0989 - loss: 2.3012\n",
            "Test accuracy: 0.10080000013113022\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "zJa4Lf76KZDM",
        "outputId": "5f20b1c1-f05c-40d1-f0d1-930d6501c654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_index = 27\n",
        "\n",
        "# Extract the test image and label\n",
        "test_image = x_test[image_index]\n",
        "test_label = np.argmax(y_test[image_index])\n",
        "\n",
        "# Reshape the test image for prediction (Keras expects a batch dimension)\n",
        "test_image_reshaped = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Make predictions on the test image\n",
        "predicted_label = np.argmax(model.predict(test_image_reshaped), axis=-1)\n",
        "\n",
        "# Plot the test image with predicted and actual labels\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label[0]}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWO9KNmgQ0VX"
      },
      "source": [
        "### Just to explore TensorFlow Implemenation of CNN.\n",
        "\n",
        "Not Required For Submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc8F7Lo_AOII",
        "outputId": "107054e4-528a-48a6-8b79-67bd294c8377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1009 - loss: 2.3027\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1013 - loss: 2.3026\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1046 - loss: 2.3026\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1025 - loss: 2.3025\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1051 - loss: 2.3025\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.1003 - loss: 2.3024\n",
            "\n",
            "Test accuracy: 0.10029999911785126\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='tanh'),\n",
        "    layers.MaxPooling2D((3, 3)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='softmax'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='SGD',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images.reshape(-1, 28, 28, 1), test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK1xXT5W7cMS"
      },
      "source": [
        "## AUTOMATED TUNING (EXETENDED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yIeVei_C8sVB"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "MLExp",
      "language": "python",
      "name": "mlexp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
