{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 694,
      "metadata": {
        "id": "hASLpyncBmvt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: 2.0.0 not found\n"
          ]
        }
      ],
      "source": [
        "!pip install -U portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jum_uBK3SA8Q"
      },
      "source": [
        "## Task - 1\n",
        "\n",
        "### PyTorch FC ANN MNIST Implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 695,
      "metadata": {
        "id": "1AShoC94SHM6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.], device='mps:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "import keras_tuner as kt\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=mps_device)\n",
        "    print (x)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 696,
      "metadata": {
        "id": "YDg8ZzyzSKpu"
      },
      "outputs": [],
      "source": [
        "# Transformations --> this is a \"pre-processing step\" that's typical for image processing methods\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize data to range [-1, 1]\n",
        "])\n",
        "# This dataset is already \"sorted\" as part of the import method, but no \"validation\" set has been selected in this case\n",
        "# Loading the FashionMNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 697,
      "metadata": {
        "id": "3DRu0tGPS0dy"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset -- later we'll see that this using the \"keras to_categorical\" method as discussed in class\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 698,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "DnFh3_pTS8fD",
        "outputId": "5dc06071-596f-47f2-90e9-846eca184a30"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#This cell is designed to display a few images from the dataset\n",
        "#It isn't necessary to run this, but it can help give a better idea of the challanges your model will face\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Displaying figures from the dataset randomly\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 699,
      "metadata": {
        "id": "_z_Aj5LWS_-f"
      },
      "outputs": [],
      "source": [
        "#Here we define the model parameters -- the general strucutre as provided here will produce a fully connected network [28x28] --> 32 --> 16 --> 10\n",
        "\n",
        "mps_device = torch.device(\"mps\")\n",
        "\n",
        "class MLP(nn.Module): #MLP stands for \"Multi-Layer Perceptron\"\n",
        "    def __init__(self, hidden_topology, hidden_activations): #this initializes the structure of the network\n",
        "        super(MLP, self).__init__()\n",
        "        self.hidden_topology = hidden_topology\n",
        "        self.hidden_activations = hidden_activations\n",
        "        self.fc1 = nn.Linear(28 * 28, self.hidden_topology[0]) ## First fully connected linear layer, 28*28 input features and 32 outputs\n",
        "        self.fcharr = []\n",
        "        for i in range(1, len(self.hidden_topology)):\n",
        "            self.fcharr.append(nn.Linear(self.hidden_topology[i-1], self.hidden_topology[i]))\n",
        "            # self.fcharr[i-1].to(mps_device)\n",
        "        self.fc3 = nn.Linear(self.hidden_topology[len(self.hidden_topology)-1], 10) ## 10 output features because MNIST has 10 target classes\n",
        "        # self.to(mps_device)\n",
        "\n",
        "\n",
        "    def forward(self, x): #this modifies the elements of the intial structure defined above\n",
        "        x = x.view(-1, 28 * 28) #the array is sent in as a vector\n",
        "        x = self.hidden_activations[0](self.fc1(x))\n",
        "        for i in range(1, len(self.hidden_topology)):\n",
        "            x = self.hidden_activations[i](self.fcharr[i-1](x))\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        # x = torch.sigmoid(self.fc1(x)) ## Applying sigmoid activation for the first layer\n",
        "        # x = torch.tanh(self.fc2(x)) ## Applying tanh activation for the second layer\n",
        "        # x = self.fc3(x) ## no modifications to the activation of the output layer\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 703,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfpEh_TyTLBa",
        "outputId": "bd6acb53-37dd-446b-a37b-3e856476f51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[32, 16] sigmoid,tanh 0.002 32\n",
            "[32, 16] sigmoid,tanh 0.002 64\n",
            "[32, 16] sigmoid,tanh 0.002 128\n",
            "[32, 16] sigmoid,tanh 0.004 32\n",
            "[32, 16] sigmoid,tanh 0.004 64\n",
            "[32, 16] sigmoid,tanh 0.004 128\n",
            "[32, 16] sigmoid,tanh 0.008 32\n",
            "[32, 16] sigmoid,tanh 0.008 64\n",
            "[32, 16] sigmoid,tanh 0.008 128\n",
            "[32, 16] sigmoid,tanh 0.02 32\n",
            "[32, 16] sigmoid,tanh 0.02 64\n",
            "[32, 16] sigmoid,tanh 0.02 128\n",
            "[32, 16] sigmoid,tanh 0.04 32\n",
            "[32, 16] sigmoid,tanh 0.04 64\n",
            "[32, 16] sigmoid,tanh 0.04 128\n",
            "[32, 16] sigmoid,tanh 0.08 32\n",
            "[32, 16] sigmoid,tanh 0.08 64\n",
            "[32, 16] sigmoid,tanh 0.08 128\n",
            "[32, 16] sigmoid,tanh 0.2 32\n",
            "[32, 16] sigmoid,tanh 0.2 64\n",
            "[32, 16] sigmoid,tanh 0.2 128\n",
            "[32, 16] tanh,tanh 0.002 32\n",
            "[32, 16] tanh,tanh 0.002 64\n",
            "[32, 16] tanh,tanh 0.002 128\n",
            "[32, 16] tanh,tanh 0.004 32\n",
            "[32, 16] tanh,tanh 0.004 64\n",
            "[32, 16] tanh,tanh 0.004 128\n",
            "[32, 16] tanh,tanh 0.008 32\n",
            "[32, 16] tanh,tanh 0.008 64\n",
            "[32, 16] tanh,tanh 0.008 128\n",
            "[32, 16] tanh,tanh 0.02 32\n",
            "[32, 16] tanh,tanh 0.02 64\n",
            "[32, 16] tanh,tanh 0.02 128\n",
            "[32, 16] tanh,tanh 0.04 32\n",
            "[32, 16] tanh,tanh 0.04 64\n",
            "[32, 16] tanh,tanh 0.04 128\n",
            "[32, 16] tanh,tanh 0.08 32\n",
            "[32, 16] tanh,tanh 0.08 64\n",
            "[32, 16] tanh,tanh 0.08 128\n",
            "[32, 16] tanh,tanh 0.2 32\n",
            "[32, 16] tanh,tanh 0.2 64\n",
            "[32, 16] tanh,tanh 0.2 128\n",
            "[32, 16] tanh,relu 0.002 32\n",
            "[32, 16] tanh,relu 0.002 64\n",
            "[32, 16] tanh,relu 0.002 128\n",
            "[32, 16] tanh,relu 0.004 32\n",
            "[32, 16] tanh,relu 0.004 64\n",
            "[32, 16] tanh,relu 0.004 128\n",
            "[32, 16] tanh,relu 0.008 32\n",
            "[32, 16] tanh,relu 0.008 64\n",
            "[32, 16] tanh,relu 0.008 128\n",
            "[32, 16] tanh,relu 0.02 32\n",
            "[32, 16] tanh,relu 0.02 64\n",
            "[32, 16] tanh,relu 0.02 128\n",
            "[32, 16] tanh,relu 0.04 32\n",
            "[32, 16] tanh,relu 0.04 64\n",
            "[32, 16] tanh,relu 0.04 128\n",
            "[32, 16] tanh,relu 0.08 32\n",
            "[32, 16] tanh,relu 0.08 64\n",
            "[32, 16] tanh,relu 0.08 128\n",
            "[32, 16] tanh,relu 0.2 32\n",
            "[32, 16] tanh,relu 0.2 64\n",
            "[32, 16] tanh,relu 0.2 128\n",
            "[24, 24] sigmoid,tanh 0.002 32\n",
            "[24, 24] sigmoid,tanh 0.002 64\n",
            "[24, 24] sigmoid,tanh 0.002 128\n",
            "[24, 24] sigmoid,tanh 0.004 32\n",
            "[24, 24] sigmoid,tanh 0.004 64\n",
            "[24, 24] sigmoid,tanh 0.004 128\n",
            "[24, 24] sigmoid,tanh 0.008 32\n",
            "[24, 24] sigmoid,tanh 0.008 64\n",
            "[24, 24] sigmoid,tanh 0.008 128\n",
            "[24, 24] sigmoid,tanh 0.02 32\n",
            "[24, 24] sigmoid,tanh 0.02 64\n",
            "[24, 24] sigmoid,tanh 0.02 128\n",
            "[24, 24] sigmoid,tanh 0.04 32\n",
            "[24, 24] sigmoid,tanh 0.04 64\n",
            "[24, 24] sigmoid,tanh 0.04 128\n",
            "[24, 24] sigmoid,tanh 0.08 32\n",
            "[24, 24] sigmoid,tanh 0.08 64\n",
            "[24, 24] sigmoid,tanh 0.08 128\n",
            "[24, 24] sigmoid,tanh 0.2 32\n",
            "[24, 24] sigmoid,tanh 0.2 64\n",
            "[24, 24] sigmoid,tanh 0.2 128\n",
            "[24, 24] tanh,tanh 0.002 32\n",
            "[24, 24] tanh,tanh 0.002 64\n",
            "[24, 24] tanh,tanh 0.002 128\n",
            "[24, 24] tanh,tanh 0.004 32\n",
            "[24, 24] tanh,tanh 0.004 64\n",
            "[24, 24] tanh,tanh 0.004 128\n",
            "[24, 24] tanh,tanh 0.008 32\n",
            "[24, 24] tanh,tanh 0.008 64\n",
            "[24, 24] tanh,tanh 0.008 128\n",
            "[24, 24] tanh,tanh 0.02 32\n",
            "[24, 24] tanh,tanh 0.02 64\n",
            "[24, 24] tanh,tanh 0.02 128\n",
            "[24, 24] tanh,tanh 0.04 32\n",
            "[24, 24] tanh,tanh 0.04 64\n",
            "[24, 24] tanh,tanh 0.04 128\n",
            "[24, 24] tanh,tanh 0.08 32\n",
            "[24, 24] tanh,tanh 0.08 64\n",
            "[24, 24] tanh,tanh 0.08 128\n",
            "[24, 24] tanh,tanh 0.2 32\n",
            "[24, 24] tanh,tanh 0.2 64\n",
            "[24, 24] tanh,tanh 0.2 128\n",
            "[24, 24] tanh,relu 0.002 32\n",
            "[24, 24] tanh,relu 0.002 64\n",
            "[24, 24] tanh,relu 0.002 128\n",
            "[24, 24] tanh,relu 0.004 32\n",
            "[24, 24] tanh,relu 0.004 64\n",
            "[24, 24] tanh,relu 0.004 128\n",
            "[24, 24] tanh,relu 0.008 32\n",
            "[24, 24] tanh,relu 0.008 64\n",
            "[24, 24] tanh,relu 0.008 128\n",
            "[24, 24] tanh,relu 0.02 32\n",
            "[24, 24] tanh,relu 0.02 64\n",
            "[24, 24] tanh,relu 0.02 128\n",
            "[24, 24] tanh,relu 0.04 32\n",
            "[24, 24] tanh,relu 0.04 64\n",
            "[24, 24] tanh,relu 0.04 128\n",
            "[24, 24] tanh,relu 0.08 32\n",
            "[24, 24] tanh,relu 0.08 64\n",
            "[24, 24] tanh,relu 0.08 128\n",
            "[24, 24] tanh,relu 0.2 32\n",
            "[24, 24] tanh,relu 0.2 64\n",
            "[24, 24] tanh,relu 0.2 128\n",
            "[64, 32] sigmoid,tanh 0.002 32\n",
            "[64, 32] sigmoid,tanh 0.002 64\n",
            "[64, 32] sigmoid,tanh 0.002 128\n",
            "[64, 32] sigmoid,tanh 0.004 32\n",
            "[64, 32] sigmoid,tanh 0.004 64\n",
            "[64, 32] sigmoid,tanh 0.004 128\n",
            "[64, 32] sigmoid,tanh 0.008 32\n",
            "[64, 32] sigmoid,tanh 0.008 64\n",
            "[64, 32] sigmoid,tanh 0.008 128\n",
            "[64, 32] sigmoid,tanh 0.02 32\n",
            "[64, 32] sigmoid,tanh 0.02 64\n",
            "[64, 32] sigmoid,tanh 0.02 128\n",
            "[64, 32] sigmoid,tanh 0.04 32\n",
            "[64, 32] sigmoid,tanh 0.04 64\n",
            "[64, 32] sigmoid,tanh 0.04 128\n",
            "[64, 32] sigmoid,tanh 0.08 32\n",
            "[64, 32] sigmoid,tanh 0.08 64\n",
            "[64, 32] sigmoid,tanh 0.08 128\n",
            "[64, 32] sigmoid,tanh 0.2 32\n",
            "[64, 32] sigmoid,tanh 0.2 64\n",
            "[64, 32] sigmoid,tanh 0.2 128\n",
            "[64, 32] tanh,tanh 0.002 32\n",
            "[64, 32] tanh,tanh 0.002 64\n",
            "[64, 32] tanh,tanh 0.002 128\n",
            "[64, 32] tanh,tanh 0.004 32\n",
            "[64, 32] tanh,tanh 0.004 64\n",
            "[64, 32] tanh,tanh 0.004 128\n",
            "[64, 32] tanh,tanh 0.008 32\n",
            "[64, 32] tanh,tanh 0.008 64\n",
            "[64, 32] tanh,tanh 0.008 128\n",
            "[64, 32] tanh,tanh 0.02 32\n",
            "[64, 32] tanh,tanh 0.02 64\n",
            "[64, 32] tanh,tanh 0.02 128\n",
            "[64, 32] tanh,tanh 0.04 32\n",
            "[64, 32] tanh,tanh 0.04 64\n",
            "[64, 32] tanh,tanh 0.04 128\n",
            "[64, 32] tanh,tanh 0.08 32\n",
            "[64, 32] tanh,tanh 0.08 64\n",
            "[64, 32] tanh,tanh 0.08 128\n",
            "[64, 32] tanh,tanh 0.2 32\n",
            "[64, 32] tanh,tanh 0.2 64\n",
            "[64, 32] tanh,tanh 0.2 128\n",
            "[64, 32] tanh,relu 0.002 32\n",
            "[64, 32] tanh,relu 0.002 64\n",
            "[64, 32] tanh,relu 0.002 128\n",
            "[64, 32] tanh,relu 0.004 32\n",
            "[64, 32] tanh,relu 0.004 64\n",
            "[64, 32] tanh,relu 0.004 128\n",
            "[64, 32] tanh,relu 0.008 32\n",
            "[64, 32] tanh,relu 0.008 64\n",
            "[64, 32] tanh,relu 0.008 128\n",
            "[64, 32] tanh,relu 0.02 32\n",
            "[64, 32] tanh,relu 0.02 64\n",
            "[64, 32] tanh,relu 0.02 128\n",
            "[64, 32] tanh,relu 0.04 32\n",
            "[64, 32] tanh,relu 0.04 64\n",
            "[64, 32] tanh,relu 0.04 128\n",
            "[64, 32] tanh,relu 0.08 32\n",
            "[64, 32] tanh,relu 0.08 64\n",
            "[64, 32] tanh,relu 0.08 128\n",
            "[64, 32] tanh,relu 0.2 32\n",
            "[64, 32] tanh,relu 0.2 64\n",
            "[64, 32] tanh,relu 0.2 128\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.002 32\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.002 64\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.002 128\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.004 32\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.004 64\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.004 128\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.008 32\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.008 64\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.008 128\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.02 32\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.02 64\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.02 128\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.04 32\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.04 64\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.04 128\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.08 32\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.08 64\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.08 128\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.2 32\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.2 64\n",
            "[16, 16, 16] sigmoid,tanh,relu 0.2 128\n",
            "[16, 16, 16] tanh,tanh,relu 0.002 32\n",
            "[16, 16, 16] tanh,tanh,relu 0.002 64\n",
            "[16, 16, 16] tanh,tanh,relu 0.002 128\n",
            "[16, 16, 16] tanh,tanh,relu 0.004 32\n",
            "[16, 16, 16] tanh,tanh,relu 0.004 64\n",
            "[16, 16, 16] tanh,tanh,relu 0.004 128\n",
            "[16, 16, 16] tanh,tanh,relu 0.008 32\n",
            "[16, 16, 16] tanh,tanh,relu 0.008 64\n",
            "[16, 16, 16] tanh,tanh,relu 0.008 128\n",
            "[16, 16, 16] tanh,tanh,relu 0.02 32\n",
            "[16, 16, 16] tanh,tanh,relu 0.02 64\n",
            "[16, 16, 16] tanh,tanh,relu 0.02 128\n",
            "[16, 16, 16] tanh,tanh,relu 0.04 32\n",
            "[16, 16, 16] tanh,tanh,relu 0.04 64\n",
            "[16, 16, 16] tanh,tanh,relu 0.04 128\n",
            "[16, 16, 16] tanh,tanh,relu 0.08 32\n",
            "[16, 16, 16] tanh,tanh,relu 0.08 64\n",
            "[16, 16, 16] tanh,tanh,relu 0.08 128\n",
            "[16, 16, 16] tanh,tanh,relu 0.2 32\n",
            "[16, 16, 16] tanh,tanh,relu 0.2 64\n",
            "[16, 16, 16] tanh,tanh,relu 0.2 128\n",
            "[16, 16, 16] tanh,relu,relu 0.002 32\n",
            "[16, 16, 16] tanh,relu,relu 0.002 64\n",
            "[16, 16, 16] tanh,relu,relu 0.002 128\n",
            "[16, 16, 16] tanh,relu,relu 0.004 32\n",
            "[16, 16, 16] tanh,relu,relu 0.004 64\n",
            "[16, 16, 16] tanh,relu,relu 0.004 128\n",
            "[16, 16, 16] tanh,relu,relu 0.008 32\n",
            "[16, 16, 16] tanh,relu,relu 0.008 64\n",
            "[16, 16, 16] tanh,relu,relu 0.008 128\n",
            "[16, 16, 16] tanh,relu,relu 0.02 32\n",
            "[16, 16, 16] tanh,relu,relu 0.02 64\n",
            "[16, 16, 16] tanh,relu,relu 0.02 128\n",
            "[16, 16, 16] tanh,relu,relu 0.04 32\n",
            "[16, 16, 16] tanh,relu,relu 0.04 64\n",
            "[16, 16, 16] tanh,relu,relu 0.04 128\n",
            "[16, 16, 16] tanh,relu,relu 0.08 32\n",
            "[16, 16, 16] tanh,relu,relu 0.08 64\n",
            "[16, 16, 16] tanh,relu,relu 0.08 128\n",
            "[16, 16, 16] tanh,relu,relu 0.2 32\n",
            "[16, 16, 16] tanh,relu,relu 0.2 64\n",
            "[16, 16, 16] tanh,relu,relu 0.2 128\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.002 32\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.002 64\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.002 128\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.004 32\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.004 64\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.004 128\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.008 32\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.008 64\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.008 128\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.02 32\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.02 64\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.02 128\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.04 32\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.04 64\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.04 128\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.08 32\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.08 64\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.08 128\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.2 32\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.2 64\n",
            "[32, 16, 8] sigmoid,tanh,relu 0.2 128\n",
            "[32, 16, 8] tanh,tanh,relu 0.002 32\n",
            "[32, 16, 8] tanh,tanh,relu 0.002 64\n",
            "[32, 16, 8] tanh,tanh,relu 0.002 128\n",
            "[32, 16, 8] tanh,tanh,relu 0.004 32\n",
            "[32, 16, 8] tanh,tanh,relu 0.004 64\n",
            "[32, 16, 8] tanh,tanh,relu 0.004 128\n",
            "[32, 16, 8] tanh,tanh,relu 0.008 32\n",
            "[32, 16, 8] tanh,tanh,relu 0.008 64\n",
            "[32, 16, 8] tanh,tanh,relu 0.008 128\n",
            "[32, 16, 8] tanh,tanh,relu 0.02 32\n",
            "[32, 16, 8] tanh,tanh,relu 0.02 64\n",
            "[32, 16, 8] tanh,tanh,relu 0.02 128\n",
            "[32, 16, 8] tanh,tanh,relu 0.04 32\n",
            "[32, 16, 8] tanh,tanh,relu 0.04 64\n",
            "[32, 16, 8] tanh,tanh,relu 0.04 128\n",
            "[32, 16, 8] tanh,tanh,relu 0.08 32\n",
            "[32, 16, 8] tanh,tanh,relu 0.08 64\n",
            "[32, 16, 8] tanh,tanh,relu 0.08 128\n",
            "[32, 16, 8] tanh,tanh,relu 0.2 32\n",
            "[32, 16, 8] tanh,tanh,relu 0.2 64\n",
            "[32, 16, 8] tanh,tanh,relu 0.2 128\n",
            "[32, 16, 8] tanh,relu,relu 0.002 32\n",
            "[32, 16, 8] tanh,relu,relu 0.002 64\n",
            "[32, 16, 8] tanh,relu,relu 0.002 128\n",
            "[32, 16, 8] tanh,relu,relu 0.004 32\n",
            "[32, 16, 8] tanh,relu,relu 0.004 64\n",
            "[32, 16, 8] tanh,relu,relu 0.004 128\n",
            "[32, 16, 8] tanh,relu,relu 0.008 32\n",
            "[32, 16, 8] tanh,relu,relu 0.008 64\n",
            "[32, 16, 8] tanh,relu,relu 0.008 128\n",
            "[32, 16, 8] tanh,relu,relu 0.02 32\n",
            "[32, 16, 8] tanh,relu,relu 0.02 64\n",
            "[32, 16, 8] tanh,relu,relu 0.02 128\n",
            "[32, 16, 8] tanh,relu,relu 0.04 32\n",
            "[32, 16, 8] tanh,relu,relu 0.04 64\n",
            "[32, 16, 8] tanh,relu,relu 0.04 128\n",
            "[32, 16, 8] tanh,relu,relu 0.08 32\n",
            "[32, 16, 8] tanh,relu,relu 0.08 64\n",
            "[32, 16, 8] tanh,relu,relu 0.08 128\n",
            "[32, 16, 8] tanh,relu,relu 0.2 32\n",
            "[32, 16, 8] tanh,relu,relu 0.2 64\n",
            "[32, 16, 8] tanh,relu,relu 0.2 128\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.002 32\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.002 64\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.002 128\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.004 32\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.004 64\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.004 128\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.008 32\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.008 64\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.008 128\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.02 32\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.02 64\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.02 128\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.04 32\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.04 64\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.04 128\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.08 32\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.08 64\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.08 128\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.2 32\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.2 64\n",
            "[64, 32, 16] sigmoid,tanh,relu 0.2 128\n",
            "[64, 32, 16] tanh,tanh,relu 0.002 32\n",
            "[64, 32, 16] tanh,tanh,relu 0.002 64\n",
            "[64, 32, 16] tanh,tanh,relu 0.002 128\n",
            "[64, 32, 16] tanh,tanh,relu 0.004 32\n",
            "[64, 32, 16] tanh,tanh,relu 0.004 64\n",
            "[64, 32, 16] tanh,tanh,relu 0.004 128\n",
            "[64, 32, 16] tanh,tanh,relu 0.008 32\n",
            "[64, 32, 16] tanh,tanh,relu 0.008 64\n",
            "[64, 32, 16] tanh,tanh,relu 0.008 128\n",
            "[64, 32, 16] tanh,tanh,relu 0.02 32\n",
            "[64, 32, 16] tanh,tanh,relu 0.02 64\n",
            "[64, 32, 16] tanh,tanh,relu 0.02 128\n",
            "[64, 32, 16] tanh,tanh,relu 0.04 32\n",
            "[64, 32, 16] tanh,tanh,relu 0.04 64\n",
            "[64, 32, 16] tanh,tanh,relu 0.04 128\n",
            "[64, 32, 16] tanh,tanh,relu 0.08 32\n",
            "[64, 32, 16] tanh,tanh,relu 0.08 64\n",
            "[64, 32, 16] tanh,tanh,relu 0.08 128\n",
            "[64, 32, 16] tanh,tanh,relu 0.2 32\n",
            "[64, 32, 16] tanh,tanh,relu 0.2 64\n",
            "[64, 32, 16] tanh,tanh,relu 0.2 128\n",
            "[64, 32, 16] tanh,relu,relu 0.002 32\n",
            "[64, 32, 16] tanh,relu,relu 0.002 64\n",
            "[64, 32, 16] tanh,relu,relu 0.002 128\n",
            "[64, 32, 16] tanh,relu,relu 0.004 32\n",
            "[64, 32, 16] tanh,relu,relu 0.004 64\n",
            "[64, 32, 16] tanh,relu,relu 0.004 128\n",
            "[64, 32, 16] tanh,relu,relu 0.008 32\n",
            "[64, 32, 16] tanh,relu,relu 0.008 64\n",
            "[64, 32, 16] tanh,relu,relu 0.008 128\n",
            "[64, 32, 16] tanh,relu,relu 0.02 32\n",
            "[64, 32, 16] tanh,relu,relu 0.02 64\n",
            "[64, 32, 16] tanh,relu,relu 0.02 128\n",
            "[64, 32, 16] tanh,relu,relu 0.04 32\n",
            "[64, 32, 16] tanh,relu,relu 0.04 64\n",
            "[64, 32, 16] tanh,relu,relu 0.04 128\n",
            "[64, 32, 16] tanh,relu,relu 0.08 32\n",
            "[64, 32, 16] tanh,relu,relu 0.08 64\n",
            "[64, 32, 16] tanh,relu,relu 0.08 128\n",
            "[64, 32, 16] tanh,relu,relu 0.2 32\n",
            "[64, 32, 16] tanh,relu,relu 0.2 64\n",
            "[64, 32, 16] tanh,relu,relu 0.2 128\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.002 32\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.002 64\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.002 128\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.004 32\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.004 64\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.004 128\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.008 32\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.008 64\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.008 128\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.02 32\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.02 64\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.02 128\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.04 32\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.04 64\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.04 128\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.08 32\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.08 64\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.08 128\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.2 32\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.2 64\n",
            "[16, 16, 16, 16] sigmoid,tanh,relu,relu 0.2 128\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.002 32\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.002 64\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.002 128\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.004 32\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.004 64\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.004 128\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.008 32\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.008 64\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.008 128\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.02 32\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.02 64\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.02 128\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.04 32\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.04 64\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.04 128\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.08 32\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.08 64\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.08 128\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.2 32\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.2 64\n",
            "[16, 16, 16, 16] tanh,tanh,relu,relu 0.2 128\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.002 32\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.002 64\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.002 128\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.004 32\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.004 64\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.004 128\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.008 32\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.008 64\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.008 128\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.02 32\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.02 64\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.02 128\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.04 32\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.04 64\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.04 128\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.08 32\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.08 64\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.08 128\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.2 32\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.2 64\n",
            "[16, 16, 16, 16] tanh,relu,relu,relu 0.2 128\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.002 32\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.002 64\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.002 128\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.004 32\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.004 64\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.004 128\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.008 32\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.008 64\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.008 128\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.02 32\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.02 64\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.02 128\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.04 32\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.04 64\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.04 128\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.08 32\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.08 64\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.08 128\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.2 32\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.2 64\n",
            "[32, 16, 16, 8] sigmoid,tanh,relu,relu 0.2 128\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.002 32\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.002 64\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.002 128\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.004 32\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.004 64\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.004 128\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.008 32\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.008 64\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.008 128\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.02 32\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.02 64\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.02 128\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.04 32\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.04 64\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.04 128\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.08 32\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.08 64\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.08 128\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.2 32\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.2 64\n",
            "[32, 16, 16, 8] tanh,tanh,relu,relu 0.2 128\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.002 32\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.002 64\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.002 128\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.004 32\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.004 64\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.004 128\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.008 32\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.008 64\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.008 128\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.02 32\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.02 64\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.02 128\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.04 32\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.04 64\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.04 128\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.08 32\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.08 64\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.08 128\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.2 32\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.2 64\n",
            "[32, 16, 16, 8] tanh,relu,relu,relu 0.2 128\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.002 32\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.002 64\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.002 128\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.004 32\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.004 64\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.004 128\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.008 32\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.008 64\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.008 128\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.02 32\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.02 64\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.02 128\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.04 32\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.04 64\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.04 128\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.08 32\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.08 64\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.08 128\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.2 32\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.2 64\n",
            "[64, 32, 24, 16] sigmoid,tanh,relu,relu 0.2 128\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.002 32\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.002 64\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.002 128\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.004 32\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.004 64\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.004 128\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.008 32\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.008 64\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.008 128\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.02 32\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.02 64\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.02 128\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.04 32\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.04 64\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.04 128\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.08 32\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.08 64\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.08 128\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.2 32\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.2 64\n",
            "[64, 32, 24, 16] tanh,tanh,relu,relu 0.2 128\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.002 32\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.002 64\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.002 128\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.004 32\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.004 64\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.004 128\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.008 32\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.008 64\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.008 128\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.02 32\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.02 64\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.02 128\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.04 32\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.04 64\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.04 128\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.08 32\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.08 64\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.08 128\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.2 32\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.2 64\n",
            "[64, 32, 24, 16] tanh,relu,relu,relu 0.2 128\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model_topologies = [\n",
        "    [32,16],\n",
        "    [32,32],\n",
        "    [24,24],\n",
        "    [24,23],\n",
        "    [64,32],\n",
        "    [16,16,16],\n",
        "    [32,16,8],\n",
        "    [64,32,16],\n",
        "    [16,16,16,16],\n",
        "    [32,16,16,8],\n",
        "    [64,32,24,16],\n",
        "]\n",
        "\n",
        "activation_functions_2_layer = [\n",
        "    [torch.sigmoid, torch.tanh],\n",
        "    [torch.tanh, torch.tanh],\n",
        "    [torch.tanh, torch.relu],\n",
        "]\n",
        "\n",
        "activation_functions_3_layer = [\n",
        "    [torch.sigmoid, torch.tanh, torch.relu],\n",
        "    [torch.tanh, torch.tanh, torch.relu],\n",
        "    [torch.tanh, torch.relu, torch.relu],\n",
        "]\n",
        "\n",
        "activation_functions_4_layer = [\n",
        "    [torch.sigmoid, torch.tanh, torch.relu, torch.relu],\n",
        "    [torch.tanh, torch.tanh, torch.relu, torch.relu],\n",
        "    [torch.tanh, torch.relu, torch.relu, torch.relu],\n",
        "]\n",
        "\n",
        "learning_rates = [0.002, 0.004, 0.008, 0.02 ,0.04, 0.08, 0.2]\n",
        "batch_sizes = [32,64,128]\n",
        "\n",
        "net_results_2_layer = []\n",
        "net_results_3_layer = []\n",
        "net_results_4_layer = []\n",
        "\n",
        "# Training and Testing loaders\n",
        "\n",
        "for i in range(len(model_topologies)):\n",
        "    model_topology = model_topologies[i]\n",
        "    net_results = []    \n",
        "    layer_count = len(model_topology)\n",
        "    if(len(model_topology) == 2):\n",
        "        activation_functions = activation_functions_2_layer\n",
        "        net_results = net_results_2_layer\n",
        "    elif(len(model_topology) == 3):\n",
        "        activation_functions = activation_functions_3_layer\n",
        "        net_results = net_results_3_layer\n",
        "    elif(len(model_topology) == 4):\n",
        "        activation_functions = activation_functions_4_layer\n",
        "        net_results = net_results_4_layer\n",
        "\n",
        "    for j in range(len(activation_functions)):\n",
        "        act_func_list = ','.join(x.__name__ for x in activation_functions[j])\n",
        "        for k in range(len(learning_rates)):\n",
        "            for m in range(len(batch_sizes)):\n",
        "                print(f'{model_topology} {act_func_list} {learning_rates[k]} {batch_sizes[m]}')\n",
        "\n",
        "                #Create string of parameters for the model\n",
        "                run_name = f'SGD_{layer_count}_layer-{model_topology}_{act_func_list}_{learning_rates[k]}_{batch_sizes[m]}'\n",
        "\n",
        "                #check if the file already exists\n",
        "                try:\n",
        "                    results_file = open(run_name + '.json', 'r')\n",
        "                    results_file.close()\n",
        "\n",
        "                    #read the json and create array\n",
        "                    results = pd.read_json(run_name + '.json', lines=True)\n",
        "                    accuracy = results['accuracy']\n",
        "                    topology = results['model_topology']\n",
        "                    act_func = results['activation_functions']\n",
        "                    learn_rate = results['learning_rate']\n",
        "                    batch_size = results['batch_size']\n",
        "\n",
        "                    #append to net_results\n",
        "                    net_results.append([accuracy, topology, act_func, learn_rate])\n",
        "                    continue\n",
        "                except:\n",
        "                    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_sizes[m], shuffle=True)\n",
        "                    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_sizes[m], shuffle=False)\n",
        "\n",
        "                    #run each model 10 times and average the results\n",
        "                    model = MLP(model_topology, activation_functions[j])\n",
        "                    criterion = nn.CrossEntropyLoss()\n",
        "                    optimizer = optim.SGD(model.parameters(), lr=learning_rates[k])\n",
        "\n",
        "                    num_epochs = 25\n",
        "                    for epoch in range(num_epochs):\n",
        "                        model.train()\n",
        "                        running_loss = 0.0\n",
        "                        for i, data in enumerate(train_loader, 0):\n",
        "                            inputs, labels = data\n",
        "                            # inputs = inputs.to(mps_device)\n",
        "                            # labels = labels.to(mps_device)\n",
        "                            optimizer.zero_grad()\n",
        "\n",
        "                            outputs = model(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "                            running_loss += loss.item()\n",
        "                            # if i % 1000 == 999:\n",
        "                            #     # print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "                            #     running_loss = 0.0\n",
        "\n",
        "                    model.eval()\n",
        "                    correct = 0\n",
        "                    total = 0\n",
        "                    with torch.no_grad():\n",
        "                        for data in test_loader:\n",
        "                            images, labels = data\n",
        "                            # images = images.to(mps_device)\n",
        "                            # labels = labels.to(mps_device)\n",
        "                            outputs = model(images)\n",
        "                            _, predicted = torch.max(outputs.data, 1)\n",
        "                            total += labels.size(0)\n",
        "                            correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    results_file = open(run_name + '.json', 'a')\n",
        "\n",
        "                    #write results to json file\n",
        "                    #{accuracy: 0.0, model_topology: [32,16], activation_functions: [sigmoid, tanh], learning_rate: 0.002}\n",
        "                    results_file.write(f'{{\"accuracy\": {100*(correct / total):.2f}, \"model_topology\": \\\"{model_topology}\\\", \"activation_functions\": \\\"{act_func_list}\\\", \"learning_rate\": {learning_rates[k]},\"batch_size\": {batch_sizes[m]}}}\\n')\n",
        "                    results_file.close()\n",
        "\n",
        "\n",
        "                    print(f'{100*(correct / total):.2f}%')\n",
        "                    net_results.append([100*(correct / total), f'{model_topology}', act_func_list, learning_rates[k], batch_sizes[m]])\n",
        "                # print(f'Model Topology: {model_topology}')\n",
        "                # print(f'Activation Functions: {activation_functions[j]}')\n",
        "                # print(f'Learning Rate: {learning_rates[k]}')\n",
        "                # print(f'Accuracy on test set: { 100*(correct / total)}%')\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 704,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "5 columns passed, passed data had 4 columns",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
            "\u001b[0;31mAssertionError\u001b[0m: 5 columns passed, passed data had 4 columns",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[704], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_results_2_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel Topology\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActivation Functions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLearning Rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBatch Size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(net_results_3_layer, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Topology\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivation Functions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch Size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m df4 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(net_results_4_layer, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Topology\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActivation Functions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch Size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
            "\u001b[0;31mValueError\u001b[0m: 5 columns passed, passed data had 4 columns"
          ]
        }
      ],
      "source": [
        "df2 = pd.DataFrame(net_results_2_layer, columns=['Accuracy', 'Model Topology', 'Activation Functions', 'Learning Rate', 'Batch Size'])\n",
        "df3 = pd.DataFrame(net_results_3_layer, columns=['Accuracy', 'Model Topology', 'Activation Functions', 'Learning Rate', 'Batch Size'])\n",
        "df4 = pd.DataFrame(net_results_4_layer, columns=['Accuracy', 'Model Topology', 'Activation Functions', 'Learning Rate', 'Batch Size'])\n",
        "\n",
        "\n",
        "#Plot accuracy vs log(learning rate) for each model topology and activation function combination\n",
        "sns.set_theme(style=\"whitegrid\", font='serif', font_scale=0.6)\n",
        "\n",
        "\n",
        "g = sns.FacetGrid(df2, row='Model Topology', col='Activation Functions', margin_titles=True)\n",
        "g.map(sns.lineplot, 'Learning Rate', 'Accuracy')\n",
        "g.set_axis_labels('Learning Rate', 'Accuracy')\n",
        "g.add_legend()\n",
        "plt.xscale('log')\n",
        "plt.show()\n",
        "\n",
        "g = sns.FacetGrid(df3, row='Model Topology', col='Activation Functions', margin_titles=True)\n",
        "g.map(sns.lineplot, 'Learning Rate', 'Accuracy')\n",
        "g.set_axis_labels('Learning Rate', 'Accuracy')\n",
        "g.add_legend()\n",
        "plt.xscale('log')\n",
        "plt.show()\n",
        "\n",
        "g = sns.FacetGrid(df4, row='Model Topology', col='Activation Functions', margin_titles=True)\n",
        "g.map(sns.lineplot, 'Learning Rate', 'Accuracy')\n",
        "g.set_axis_labels('Learning Rate', 'Accuracy')\n",
        "g.add_legend()\n",
        "plt.xscale('log')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfYr_0XlT-Cb",
        "outputId": "e298b73f-543d-49a6-dbf5-b3c0099fae75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 72.86%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: { 100*(correct / total)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "kNM8-ijzUE9w",
        "outputId": "a07af0ed-e731-461f-d8c1-35750b29394c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_index = 27\n",
        "test_image, test_label = test_dataset[image_index]\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(test_image.unsqueeze(0))\n",
        "    _, predicted_label = torch.max(output, 1)\n",
        "\n",
        "test_image_numpy = test_image.squeeze().numpy()\n",
        "\n",
        "plt.imshow(test_image_numpy, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label.item()}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoypxOXgGjuC"
      },
      "source": [
        "Notes for Part 1\n",
        "\n",
        "1. Activation fucntion:\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))  # Change activation function here\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "2. loss function and optimizer\n",
        "\n",
        "model = Net()\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Change loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "3. ~adding a dropout layer\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "        self.dropout = torch.nn.Dropout(0.2)  # Add a Dropout layer here\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply Dropout\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "4. model configurations / epochs\n",
        "\n",
        "epochs = 10  # Change number of epochs\n",
        "for epoch in range(epochs):\n",
        "    # Training loop\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Training steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3IIK5kzHGH0"
      },
      "source": [
        "## Task - 2\n",
        "\n",
        "### PyTorch FC ANN FMNIST Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "_aWMlQ33ByRO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "jOCzfnBvB_bQ"
      },
      "outputs": [],
      "source": [
        "# Transformations --> this is a \"pre-processing step\" that's typical for image processing methods\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize data to range [-1, 1]\n",
        "])\n",
        "# This dataset is already \"sorted\" as part of the import method, but no \"validation\" set has been selected in this case\n",
        "# Loading the FashionMNIST dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Training and Testing loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "id": "jZk_FS9JCLOH"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset -- later we'll see that this using the \"keras to_categorical\" method as discussed in class\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "ykrRIGSdCMu5",
        "outputId": "a6737577-19d7-459e-aa83-ccebed56246c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#This cell is designed to display a few images from the dataset\n",
        "#It isn't necessary to run this, but it can help give a better idea of the challanges your model will face\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Displaying figures from the dataset randomly\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "id": "3JLJ0ZFCER5m"
      },
      "outputs": [],
      "source": [
        "#Here we define the model parameters -- the general strucutre as provided here will produce a fully connected network [28x28] --> 32 --> 16 --> 10\n",
        "class MLP(nn.Module): #MLP stands for \"Multi-Layer Perceptron\"\n",
        "    def __init__(self): #this initializes the structure of the network\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 32) ## First fully connected linear layer, 28*28 input features and 32 outputs\n",
        "        self.fc2 = nn.Linear(32 , 16) ## Second fully connected linear layer, 32 inputs and 16 outputs\n",
        "        self.fc3 = nn.Linear(16, 10) ## 10 output features because MNIST has 10 target classes\n",
        "\n",
        "    def forward(self, x): #this modifies the elements of the intial structure defined above\n",
        "        x = x.view(-1, 28 * 28) #the array is sent in as a vector\n",
        "        x = torch.sigmoid(self.fc1(x)) ## Applying sigmoid activation for the first layer\n",
        "        x = torch.tanh(self.fc2(x)) ## Applying tanh activation for the second layer\n",
        "        x = self.fc3(x) ## no modifications to the activation of the output layer\n",
        "        return x\n",
        "\n",
        "# Initializing the neural network\n",
        "model = MLP()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hFOEXCPEVTw",
        "outputId": "6c4d33e6-8624-4eae-d51b-7008e6826780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 100, Loss: 2.3092327547073364\n",
            "Epoch 1, Batch 200, Loss: 2.2942226004600523\n",
            "Epoch 1, Batch 300, Loss: 2.279485487937927\n",
            "Epoch 1, Batch 400, Loss: 2.2643858671188353\n",
            "Epoch 1, Batch 500, Loss: 2.2518870854377746\n",
            "Epoch 1, Batch 600, Loss: 2.2394341468811034\n",
            "Epoch 1, Batch 700, Loss: 2.2233759331703187\n",
            "Epoch 1, Batch 800, Loss: 2.2101558160781862\n",
            "Epoch 1, Batch 900, Loss: 2.1955674505233764\n",
            "Epoch 2, Batch 100, Loss: 2.1743762993812563\n",
            "Epoch 2, Batch 200, Loss: 2.158717300891876\n",
            "Epoch 2, Batch 300, Loss: 2.138843719959259\n",
            "Epoch 2, Batch 400, Loss: 2.124714708328247\n",
            "Epoch 2, Batch 500, Loss: 2.099507575035095\n",
            "Epoch 2, Batch 600, Loss: 2.0802184104919434\n",
            "Epoch 2, Batch 700, Loss: 2.062397301197052\n",
            "Epoch 2, Batch 800, Loss: 2.034111989736557\n",
            "Epoch 2, Batch 900, Loss: 2.011344039440155\n",
            "Epoch 3, Batch 100, Loss: 1.9797982275485992\n",
            "Epoch 3, Batch 200, Loss: 1.953240214586258\n",
            "Epoch 3, Batch 300, Loss: 1.9322712624073028\n",
            "Epoch 3, Batch 400, Loss: 1.9050440895557403\n",
            "Epoch 3, Batch 500, Loss: 1.8749271929264069\n",
            "Epoch 3, Batch 600, Loss: 1.860140573978424\n",
            "Epoch 3, Batch 700, Loss: 1.8346011817455292\n",
            "Epoch 3, Batch 800, Loss: 1.800904973745346\n",
            "Epoch 3, Batch 900, Loss: 1.789574033021927\n",
            "Epoch 4, Batch 100, Loss: 1.7498372435569762\n",
            "Epoch 4, Batch 200, Loss: 1.7256116366386414\n",
            "Epoch 4, Batch 300, Loss: 1.7029189443588257\n",
            "Epoch 4, Batch 400, Loss: 1.6802574586868286\n",
            "Epoch 4, Batch 500, Loss: 1.6592220866680145\n",
            "Epoch 4, Batch 600, Loss: 1.6397797858715057\n",
            "Epoch 4, Batch 700, Loss: 1.617271054983139\n",
            "Epoch 4, Batch 800, Loss: 1.6042920601367952\n",
            "Epoch 4, Batch 900, Loss: 1.5748184144496917\n",
            "Epoch 5, Batch 100, Loss: 1.5522019112110137\n",
            "Epoch 5, Batch 200, Loss: 1.5345584881305694\n",
            "Epoch 5, Batch 300, Loss: 1.5261085247993469\n",
            "Epoch 5, Batch 400, Loss: 1.50809588432312\n",
            "Epoch 5, Batch 500, Loss: 1.4916134464740753\n",
            "Epoch 5, Batch 600, Loss: 1.4843992710113525\n",
            "Epoch 5, Batch 700, Loss: 1.468581247329712\n",
            "Epoch 5, Batch 800, Loss: 1.4456808125972749\n",
            "Epoch 5, Batch 900, Loss: 1.4376325190067292\n",
            "Epoch 6, Batch 100, Loss: 1.4117704629898071\n",
            "Epoch 6, Batch 200, Loss: 1.398487503528595\n",
            "Epoch 6, Batch 300, Loss: 1.393402614593506\n",
            "Epoch 6, Batch 400, Loss: 1.3792809200286866\n",
            "Epoch 6, Batch 500, Loss: 1.375633910894394\n",
            "Epoch 6, Batch 600, Loss: 1.3497878789901734\n",
            "Epoch 6, Batch 700, Loss: 1.3571362686157227\n",
            "Epoch 6, Batch 800, Loss: 1.3375901806354522\n",
            "Epoch 6, Batch 900, Loss: 1.3312219393253326\n",
            "Epoch 7, Batch 100, Loss: 1.3096948063373566\n",
            "Epoch 7, Batch 200, Loss: 1.3091510438919067\n",
            "Epoch 7, Batch 300, Loss: 1.29644460439682\n",
            "Epoch 7, Batch 400, Loss: 1.2839136111736298\n",
            "Epoch 7, Batch 500, Loss: 1.2752650010585784\n",
            "Epoch 7, Batch 600, Loss: 1.2599953305721283\n",
            "Epoch 7, Batch 700, Loss: 1.2547466146945954\n",
            "Epoch 7, Batch 800, Loss: 1.2521281850337982\n",
            "Epoch 7, Batch 900, Loss: 1.2342652809619903\n",
            "Epoch 8, Batch 100, Loss: 1.2330012500286103\n",
            "Epoch 8, Batch 200, Loss: 1.2291939043998719\n",
            "Epoch 8, Batch 300, Loss: 1.2167307233810425\n",
            "Epoch 8, Batch 400, Loss: 1.2013589584827422\n",
            "Epoch 8, Batch 500, Loss: 1.1916854393482208\n",
            "Epoch 8, Batch 600, Loss: 1.1832420217990876\n",
            "Epoch 8, Batch 700, Loss: 1.172174460887909\n",
            "Epoch 8, Batch 800, Loss: 1.1797458112239838\n",
            "Epoch 8, Batch 900, Loss: 1.161191291809082\n",
            "Epoch 9, Batch 100, Loss: 1.1404451191425324\n",
            "Epoch 9, Batch 200, Loss: 1.1478449487686158\n",
            "Epoch 9, Batch 300, Loss: 1.1341091680526734\n",
            "Epoch 9, Batch 400, Loss: 1.137139585018158\n",
            "Epoch 9, Batch 500, Loss: 1.133464161157608\n",
            "Epoch 9, Batch 600, Loss: 1.121433652639389\n",
            "Epoch 9, Batch 700, Loss: 1.128161900639534\n",
            "Epoch 9, Batch 800, Loss: 1.1149428981542586\n",
            "Epoch 9, Batch 900, Loss: 1.104666547179222\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
        "\n",
        "# Training the neural network\n",
        "num_epochs = 9\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNMCpk60EaXr",
        "outputId": "c8ffbf3e-bd21-4e29-8428-8405792a0d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 0.6422%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: { correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "J2GkmLeQEeZV",
        "outputId": "cb5bae66-d3d2-4163-deef-5828aad6b068"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_index = 27\n",
        "test_image, test_label = test_dataset[image_index]\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(test_image.unsqueeze(0))\n",
        "    _, predicted_label = torch.max(output, 1)\n",
        "\n",
        "test_image_numpy = test_image.squeeze().numpy()\n",
        "\n",
        "plt.imshow(test_image_numpy, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label.item()}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5nxrEoAHAUX"
      },
      "source": [
        "## PART - 3\n",
        "\n",
        "### FMNIST CNN Implimentation with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "ccRJi8VXH3_O"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "k41uN-aAIH6Y"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_MUVyZ5Iksr",
        "outputId": "fee20814-4805-46b6-9c2a-cea97192b605"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "AEoqWEFz5Ms-"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_tkHuwEK7B",
        "outputId": "6914193e-b027-4100-ce9b-c27788c30802"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/thomasjones/.pyenv/versions/3.10.15/envs/MLExp/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='sigmoid', input_shape=(28, 28, 1)),  # 16 filters (reduced), 3x3 kernel\n",
        "    MaxPooling2D(pool_size=(5, 5)),  # Max pooling with 2x2 pool size\n",
        "    # Flatten the output before passing to Dense layers\n",
        "    Flatten(),\n",
        "    Dense(64, activation='softmax'),  # Reduced from 128 to 64 units\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 units for classification\n",
        "])\n",
        "\n",
        "## change the architecture with CONV2D, Pooling, and Dense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "nPfHtKytJd9Q"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 5\n",
        "batch_size = 48\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=SGD(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlPkc9auJkET",
        "outputId": "ed426026-a519-43d4-a811-039b74e7c7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.0988 - loss: 2.3026\n",
            "Epoch 2/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1070 - loss: 2.3021\n",
            "Epoch 3/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1286 - loss: 2.3018\n",
            "Epoch 4/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1431 - loss: 2.3014\n",
            "Epoch 5/5\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.1171 - loss: 2.3006\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1213 - loss: 2.2994\n",
            "Test accuracy: 0.120899997651577\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig5GXhcG5fy6",
        "outputId": "b41b841c-b2e6-4520-e664-518039d33b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.1187 - loss: 2.2987 - val_accuracy: 0.0981 - val_loss: 2.2965\n",
            "Epoch 2/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.1349 - loss: 2.2947 - val_accuracy: 0.1762 - val_loss: 2.2882\n",
            "Epoch 3/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.1593 - loss: 2.2827 - val_accuracy: 0.1956 - val_loss: 2.2520\n",
            "Epoch 4/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.1958 - loss: 2.2301 - val_accuracy: 0.1882 - val_loss: 2.1444\n",
            "Epoch 5/5\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.1995 - loss: 2.1159 - val_accuracy: 0.2118 - val_loss: 2.0327\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2128 - loss: 2.0379\n",
            "Test accuracy: 0.21330000460147858\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "zJa4Lf76KZDM",
        "outputId": "5f20b1c1-f05c-40d1-f0d1-930d6501c654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x480181f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_index = 27\n",
        "\n",
        "# Extract the test image and label\n",
        "test_image = x_test[image_index]\n",
        "test_label = np.argmax(y_test[image_index])\n",
        "\n",
        "# Reshape the test image for prediction (Keras expects a batch dimension)\n",
        "test_image_reshaped = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Make predictions on the test image\n",
        "predicted_label = np.argmax(model.predict(test_image_reshaped), axis=-1)\n",
        "\n",
        "# Plot the test image with predicted and actual labels\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label[0]}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWO9KNmgQ0VX"
      },
      "source": [
        "### Just to explore TensorFlow Implemenation of CNN.\n",
        "\n",
        "Not Required For Submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc8F7Lo_AOII",
        "outputId": "107054e4-528a-48a6-8b79-67bd294c8377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 2.3027\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1005 - loss: 2.3026\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 2.3026\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1016 - loss: 2.3026\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1019 - loss: 2.3026\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.1615 - loss: 2.3025\n",
            "\n",
            "Test accuracy: 0.1615000069141388\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='tanh'),\n",
        "    layers.MaxPooling2D((3, 3)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='softmax'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='SGD',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images.reshape(-1, 28, 28, 1), test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK1xXT5W7cMS"
      },
      "source": [
        "## AUTOMATED TUNING (EXETENDED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "yIeVei_C8sVB"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "MLExp",
      "language": "python",
      "name": "mlexp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
